"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[5233],{39921:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>d,contentTitle:()=>l,default:()=>g,frontMatter:()=>i,metadata:()=>c,toc:()=>p});var o=n(87462),t=(n(67294),n(3905));const s=n.p+"assets/images/self_consistency-b0397f2f058a64fe8ceceeb2ffc5b0c4.webp";var r=n(39145);const i={sidebar_position:5},l="\ud83d\udfe1 Autoconsistencia",c={unversionedId:"intermediate/self_consistency",id:"intermediate/self_consistency",title:"\ud83d\udfe1 Autoconsistencia",description:"Autoconsistencia(@wang2022selfconsistency) es un seguimiento de %%CoT|prompting de CoT%% que genera",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/intermediate/self_consistency.md",sourceDirName:"intermediate",slug:"/intermediate/self_consistency",permalink:"/es/docs/intermediate/self_consistency",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/intermediate/self_consistency.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe2 Zero Shot Chain of Thought",permalink:"/es/docs/intermediate/zero_shot_cot"},next:{title:"\ud83d\udfe1 Generated Knowledge",permalink:"/es/docs/intermediate/generated_knowledge"}},d={},p=[{value:"Ejemplo",id:"ejemplo",level:2},{value:"Resultados",id:"resultados",level:2},{value:"Notas",id:"notas",level:2}],u={toc:p},m="wrapper";function g(e){let{components:a,...n}=e;return(0,t.kt)(m,(0,o.Z)({},u,n,{components:a,mdxType:"MDXLayout"}),(0,t.kt)("h1",{id:"-autoconsistencia"},"\ud83d\udfe1 Autoconsistencia"),(0,t.kt)("p",null,"Autoconsistencia",(0,t.kt)("sup",{parentName:"p",id:"fnref-1"},(0,t.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," es un seguimiento de ",(0,t.kt)("a",{parentName:"p",id:"prompting de CoT_2_22_1695412786847","data-tooltip-html":"La idea principal de CoT es que al mostrarle al LLM algunos ejemplos de few-shot donde se explica el proceso de razonamiento en los ejemplos, el LLM tambi\xe9n mostrar\xe1 el proceso de razonamiento al responder a la solicitud.","data-tooltip-place":"top"},"CoT"),(0,t.kt)(r.u,{anchorId:"prompting de CoT_2_22_1695412786847",clickable:!0,mdxType:"Tooltip"})," que genera\nm\xfaltiples cadenas de pensamiento en lugar de solo una, luego toma la respuesta mayoritaria\ncomo la respuesta final."),(0,t.kt)("p",null,'En la figura a continuaci\xf3n, el prompt de la izquierda est\xe1 escrito utilizando el paradigma Few-Shot-CoT.\nUsando este prompt, se generan m\xfaltiples cadenas de pensamiento de manera independiente.\nLas respuestas se extraen de cada una y la respuesta final se calcula "marginalizando\nlas rutas de razonamiento". En la pr\xe1ctica, esto significa tomar la respuesta mayoritaria.'),(0,t.kt)("div",{style:{textAlign:"center"}},(0,t.kt)("img",{src:s,style:{width:"750px"}})),(0,t.kt)("div",{style:{textAlign:"center"}},"Autoconsistencia (Wang et al.)"),(0,t.kt)("h2",{id:"ejemplo"},"Ejemplo"),(0,t.kt)("p",null,"Consideremos un ejemplo sencillo de an\xe1lisis de correos electr\xf3nicos. Supongamos que eres una empresa de software y recibes cientos de correos electr\xf3nicos al d\xeda. Quieres usar un modelo para clasificar los correos electr\xf3nicos como importantes o no importantes, para que puedas priorizar aquellos que puedan tener un gran impacto en tu negocio."),(0,t.kt)("p",null,"Aqu\xed hay un ejemplo de correo electr\xf3nico que podr\xedas recibir:"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre"},"Hola,\n\nHe descubierto una gran vulnerabilidad de seguridad en su sistema. Aunque no es f\xe1cil de usar, es posible acceder a los datos de todos sus usuarios. He adjuntado una prueba de concepto. Por favor, solucione este problema lo antes posible.\n\nSaludos cordiales,\n\nDonny\n")),(0,t.kt)("p",null,"Vamos a poner eso en un prompt:"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre"},"Hola,\n\nHe descubierto una vulnerabilidad de seguridad importante en su sistema. Aunque no es f\xe1cil de usar, es posible obtener acceso a todos los datos de sus usuarios. Adjunto una prueba de concepto. Por favor, solucione este problema lo antes posible.\n\nSaludos,\n\nDonny\n\nClasifique el correo electr\xf3nico anterior como IMPORTANTE o NO IMPORTANTE en relaci\xf3n con una empresa de software. Pensemos paso a paso.\n")),(0,t.kt)("p",null,"Ahora, usaremos el prompt anterior para generar varias completaciones/cadenas de pensamiento separadas. Aqu\xed hay algunos ejemplos:"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"\x3c!-- highlight-start --\x3e\n- El remitente ha descubierto una vulnerabilidad de seguridad importante en el sistema. Esto es importante porque podr\xeda conducir a una violaci\xf3n de datos. Clasificar\xeda este correo electr\xf3nico como IMPORTANTE.\n\x3c!-- highlight-end --\x3e\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"\x3c!-- highlight-start --\x3e\n\n- El remitente ha descubierto una vulnerabilidad de seguridad importante en el sistema, pero no ha proporcionado ninguna prueba de concepto y no es f\xe1cil de usar. Clasificar\xeda este correo electr\xf3nico como NO IMPORTANTE.\n\x3c!-- highlight-end --\x3e\n")),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"\x3c!-- highlight-start --\x3e\n\n- El remitente probablemente sea un hacker y pueda tener acceso al sistema. Esto es importante porque podr\xeda conducir a una violaci\xf3n de datos. Clasificar\xeda este correo electr\xf3nico como IMPORTANTE.\n\x3c!-- highlight-end --\x3e\n")),(0,t.kt)("p",null,"Al generar m\xfaltiples cadenas de pensamiento y tomar la respuesta m\xe1s com\xfan (",(0,t.kt)("inlineCode",{parentName:"p"},"IMPORTANTE"),"), podemos obtener una respuesta m\xe1s consistentemente correcta de GPT-3."),(0,t.kt)("h2",{id:"resultados"},"Resultados"),(0,t.kt)("p",null,"Self-consistency ha demostrado mejorar los resultados en tareas de razonamiento aritm\xe9tico, de sentido com\xfan y simb\xf3lico."),(0,t.kt)("p",null,"Incluso cuando se encontr\xf3 que CoT regular era ineficaz",(0,t.kt)("sup",{parentName:"p",id:"fnref-2"},(0,t.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),", self-consistency todav\xeda fue capaz de mejorar los resultados."),(0,t.kt)("h2",{id:"notas"},"Notas"),(0,t.kt)("p",null,"Wang et al. discuten un m\xe9todo m\xe1s complejo para marginalizar los caminos de razonamiento, que se ocupa de las probabilidades generadas por LLM para cada cadena de pensamiento. Sin embargo, no utilizan este m\xe9todo en sus experimentos, y la votaci\xf3n mayoritaria parece tener generalmente el mismo o mejor rendimiento."),(0,t.kt)("div",{className:"footnotes"},(0,t.kt)("hr",{parentName:"div"}),(0,t.kt)("ol",{parentName:"div"},(0,t.kt)("li",{parentName:"ol",id:"fn-1"},"Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,t.kt)("li",{parentName:"ol",id:"fn-2"},"Ye, X., & Durrett, G. (2022). The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}g.isMDXComponent=!0}}]);