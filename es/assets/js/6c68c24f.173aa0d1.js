"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[33],{3905:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>f});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function o(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function i(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?o(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function s(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=t.createContext({}),l=function(e){var a=t.useContext(c),n=a;return e&&(n="function"==typeof e?e(a):i(i({},a),e)),n},p=function(e){var a=l(e.components);return t.createElement(c.Provider,{value:a},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},m=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=l(n),m=r,f=u["".concat(c,".").concat(m)]||u[m]||d[m]||o;return n?t.createElement(f,i(i({ref:a},p),{},{components:n})):t.createElement(f,i({ref:a},p))}));function f(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var s={};for(var c in a)hasOwnProperty.call(a,c)&&(s[c]=a[c]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var l=2;l<o;l++)i[l]=n[l];return t.createElement.apply(null,i)}return t.createElement.apply(null,n)}m.displayName="MDXCreateElement"},40167:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>p,contentTitle:()=>c,default:()=>y,frontMatter:()=>s,metadata:()=>l,toc:()=>u});var t=n(87462),r=(n(67294),n(3905));const o=n.p+"assets/images/react_qa-c10be33ab46c41e5bf4dee9066df3e41.webp",i=n.p+"assets/images/react_performance-80d12fa8026a0599d05fd2dabcc8a283.webp",s={sidebar_position:3},c="\ud83d\udfe1 LLMs que razonan y act\xfaan",l={unversionedId:"advanced_applications/react",id:"advanced_applications/react",title:"\ud83d\udfe1 LLMs que razonan y act\xfaan",description:"ReAct (@yao2022react) (razonamiento, acci\xf3n) es un paradigma para permitir que los modelos de lenguaje resuelvan tareas complejas utilizando el razonamiento del lenguaje natural. ReAct est\xe1 dise\xf1ado para tareas en las que el LLM tiene permitido realizar ciertas acciones. Por ejemplo, como en un sistema MRKL, un LLM puede interactuar con APIs externas para obtener informaci\xf3n. Cuando se le hace una pregunta, el LLM podr\xeda elegir realizar una acci\xf3n para recuperar informaci\xf3n, y luego responder la pregunta bas\xe1ndose en la informaci\xf3n recuperada.",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/advanced_applications/react.md",sourceDirName:"advanced_applications",slug:"/advanced_applications/react",permalink:"/es/docs/advanced_applications/react",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/advanced_applications/react.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe1 LLMs Utilizando Herramientas",permalink:"/es/docs/advanced_applications/mrkl"},next:{title:"\ud83d\udfe1 Codigo como Razonamiento",permalink:"/es/docs/advanced_applications/pal"}},p={},u=[{value:"Resultados",id:"resultados",level:2}],d=(m="LazyLoadImage",function(e){return console.warn("Component "+m+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var m;const f={toc:u},g="wrapper";function y(e){let{components:a,...n}=e;return(0,r.kt)(g,(0,t.Z)({},f,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"-llms-que-razonan-y-act\xfaan"},"\ud83d\udfe1 LLMs que razonan y act\xfaan"),(0,r.kt)("p",null,"ReAct",(0,r.kt)("sup",{parentName:"p",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," (razonamiento, acci\xf3n) es un paradigma para permitir que los modelos de lenguaje resuelvan tareas complejas utilizando el razonamiento del lenguaje natural. ReAct est\xe1 dise\xf1ado para tareas en las que el LLM tiene permitido realizar ciertas acciones. Por ejemplo, como en un sistema MRKL, un LLM puede interactuar con APIs externas para obtener informaci\xf3n. Cuando se le hace una pregunta, el LLM podr\xeda elegir realizar una acci\xf3n para recuperar informaci\xf3n, y luego responder la pregunta bas\xe1ndose en la informaci\xf3n recuperada."),(0,r.kt)("p",null,"Los sistemas ReAct se pueden pensar como sistemas MRKL, con la capacidad adicional de ",(0,r.kt)("strong",{parentName:"p"},"razonar sobre")," las acciones que pueden realizar."),(0,r.kt)("p",null,"Examinemos la siguiente imagen. La pregunta en el cuadro superior proviene de HotPotQA",(0,r.kt)("sup",{parentName:"p",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),", un conjunto de datos de preguntas y respuestas que requiere un razonamiento complejo. ReAct puede responder la pregunta primero razonando sobre ella (Pensamiento 1), y luego realizando una acci\xf3n (Acci\xf3n 1) para enviar una consulta a Google. Luego recibe una observaci\xf3n (Obs 1) y contin\xfaa con este ciclo de pensamiento, acci\xf3n, observaci\xf3n hasta que llega a una conclusi\xf3n (Acci\xf3n 3)."),(0,r.kt)("div",{style:{textAlign:"center"}},(0,r.kt)("img",{src:o,style:{width:"500px"}})),(0,r.kt)("div",{style:{textAlign:"center"}},"Sistema ReAct (Yao et al.)"),(0,r.kt)("p",null,"Los lectores con conocimientos de aprendizaje por refuerzo pueden reconocer este proceso como similar al ciclo cl\xe1sico de RL de estado, acci\xf3n, recompensa, estado,.... ReAct proporciona una formalizaci\xf3n para esto en su art\xedculo."),(0,r.kt)("h2",{id:"resultados"},"Resultados"),(0,r.kt)("p",null,"Google utiliz\xf3 el LLM PaLM",(0,r.kt)("sup",{parentName:"p",id:"fnref-3"},(0,r.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3"))," en experimentos con ReAct. Las comparaciones con la solicitud est\xe1ndar (solo pregunta), CoT y otras configuraciones muestran que el rendimiento de ReAct es prometedor para tareas de razonamiento complejas. Google tambi\xe9n realiza estudios en el conjunto de datos fever",(0,r.kt)("sup",{parentName:"p",id:"fnref-4"},(0,r.kt)("a",{parentName:"sup",href:"#fn-4",className:"footnote-ref"},"4")),", que cubre la extracci\xf3n y verificaci\xf3n de hechos."),(0,r.kt)("div",{style:{textAlign:"center"}},(0,r.kt)(d,{src:i,style:{width:"500px"},mdxType:"LazyLoadImage"})),(0,r.kt)("div",{style:{textAlign:"center"}},"Resultados de ReAct (Yao et al.)"),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., & Manning, C. D. (2018). HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-3"},"Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., \u2026 Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-4"},"Thorne, J., Vlachos, A., Christodoulopoulos, C., & Mittal, A. (2018). FEVER: a large-scale dataset for Fact Extraction and VERification.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-4",className:"footnote-backref"},"\u21a9")))))}y.isMDXComponent=!0}}]);