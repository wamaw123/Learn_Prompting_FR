"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[1025],{3905:(e,a,o)=>{o.d(a,{Zo:()=>u,kt:()=>f});var n=o(67294);function t(e,a,o){return a in e?Object.defineProperty(e,a,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[a]=o,e}function r(e,a){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),o.push.apply(o,n)}return o}function s(e){for(var a=1;a<arguments.length;a++){var o=null!=arguments[a]?arguments[a]:{};a%2?r(Object(o),!0).forEach((function(a){t(e,a,o[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(o,a))}))}return e}function i(e,a){if(null==e)return{};var o,n,t=function(e,a){if(null==e)return{};var o,n,t={},r=Object.keys(e);for(n=0;n<r.length;n++)o=r[n],a.indexOf(o)>=0||(t[o]=e[o]);return t}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)o=r[n],a.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(t[o]=e[o])}return t}var l=n.createContext({}),d=function(e){var a=n.useContext(l),o=a;return e&&(o="function"==typeof e?e(a):s(s({},a),e)),o},u=function(e){var a=d(e.components);return n.createElement(l.Provider,{value:a},e.children)},c="mdxType",p={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},m=n.forwardRef((function(e,a){var o=e.components,t=e.mdxType,r=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),c=d(o),m=t,f=c["".concat(l,".").concat(m)]||c[m]||p[m]||r;return o?n.createElement(f,s(s({ref:a},u),{},{components:o})):n.createElement(f,s({ref:a},u))}));function f(e,a){var o=arguments,t=a&&a.mdxType;if("string"==typeof e||t){var r=o.length,s=new Array(r);s[0]=m;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[c]="string"==typeof e?e:t,s[1]=i;for(var d=2;d<r;d++)s[d]=o[d];return n.createElement.apply(null,s)}return n.createElement.apply(null,o)}m.displayName="MDXCreateElement"},40377:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var n=o(87462),t=(o(67294),o(3905));const r={sidebar_position:90},s="\ud83d\udcd9 Referencia de Vocabulario",i={unversionedId:"vocabulary",id:"vocabulary",title:"\ud83d\udcd9 Referencia de Vocabulario",description:"Por favor, consulte esta p\xe1gina para obtener una lista de t\xe9rminos y conceptos que utilizaremos a lo largo de este curso.",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/vocabulary.md",sourceDirName:".",slug:"/vocabulary",permalink:"/es/docs/vocabulary",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/vocabulary.md",tags:[],version:"current",sidebarPosition:90,frontMatter:{sidebar_position:90},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe2 Generaci\xf3n de m\xfasica",permalink:"/es/docs/miscl/music"},next:{title:"\ud83d\udcda Bibliography",permalink:"/es/docs/bibliography"}},l={},d=[{value:"Modelos de Lenguaje Grande (LLMs), Modelos de Lenguaje Pre-entrenados (PLMs) (@branch2022evaluating), Modelos de Lenguaje (LMs) y modelos base",id:"modelos-de-lenguaje-grande-llms-modelos-de-lenguaje-pre-entrenados-plms-branch2022evaluating-modelos-de-lenguaje-lms-y-modelos-base",level:4},{value:"Modelos de Lenguaje con M\xe1scara (MLMs)",id:"modelos-de-lenguaje-con-m\xe1scara-mlms",level:4},{value:"Etiquetas",id:"etiquetas",level:4},{value:"Espacio de Etiquetas",id:"espacio-de-etiquetas",level:4},{value:"An\xe1lisis de Sentimiento",id:"an\xe1lisis-de-sentimiento",level:4},{value:"&quot;Modelo&quot; vs. &quot;AI&quot; vs. &quot;LLM&quot;",id:"modelo-vs-ai-vs-llm",level:4},{value:"Verbalizador",id:"verbalizador",level:4},{value:"Reinforcement Learning from Human Feedback (RLHF)",id:"reinforcement-learning-from-human-feedback-rlhf",level:4}],u={toc:d},c="wrapper";function p(e){let{components:a,...o}=e;return(0,t.kt)(c,(0,n.Z)({},u,o,{components:a,mdxType:"MDXLayout"}),(0,t.kt)("h1",{id:"-referencia-de-vocabulario"},"\ud83d\udcd9 Referencia de Vocabulario"),(0,t.kt)("p",null,"Por favor, consulte esta p\xe1gina para obtener una lista de t\xe9rminos y conceptos que utilizaremos a lo largo de este curso."),(0,t.kt)("h4",{id:"modelos-de-lenguaje-grande-llms-modelos-de-lenguaje-pre-entrenados-plms-branch2022evaluating-modelos-de-lenguaje-lms-y-modelos-base"},"Modelos de Lenguaje Grande (LLMs), Modelos de Lenguaje Pre-entrenados (PLMs)",(0,t.kt)("sup",{parentName:"h4",id:"fnref-1"},(0,t.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),", Modelos de Lenguaje (LMs) y modelos base"),(0,t.kt)("p",null,"Estos t\xe9rminos se refieren m\xe1s o menos a lo mismo: AIs grandes (redes neuronales), que por lo general se han entrenado en una gran cantidad de texto."),(0,t.kt)("h4",{id:"modelos-de-lenguaje-con-m\xe1scara-mlms"},"Modelos de Lenguaje con M\xe1scara (MLMs)"),(0,t.kt)("p",null,"Los MLMs son un tipo de modelo de NLP que tienen un token especial, generalmente ",(0,t.kt)("inlineCode",{parentName:"p"},"[MASK]"),', que se sustituye por una palabra del vocabulario. El modelo luego predice la palabra que se enmascar\xf3. Por ejemplo, si la oraci\xf3n es "El perro est\xe1 ',"[MASK]",' al gato", el modelo predecir\xe1 "persiguiendo" con alta probabilidad.'),(0,t.kt)("h4",{id:"etiquetas"},"Etiquetas"),(0,t.kt)("p",null,"El concepto de etiquetas se comprende mejor con un ejemplo."),(0,t.kt)("p",null,'Digamos que queremos clasificar algunos tweets como "ofensivos" o "no ofensivos". Si tenemos una lista de tweets y su correspondiente ',(0,t.kt)("em",{parentName:"p"},"etiqueta")," (ofensivo o no ofensivo), podemos entrenar un modelo para clasificar si los tweets son ofensivos o no. Las etiquetas son generalmente solo posibilidades para la tarea de clasificaci\xf3n."),(0,t.kt)("h4",{id:"espacio-de-etiquetas"},"Espacio de Etiquetas"),(0,t.kt)("p",null,'Todas las posibles etiquetas para una tarea dada ("ofensivo" y "no ofensivo" para el ejemplo anterior).'),(0,t.kt)("h4",{id:"an\xe1lisis-de-sentimiento"},"An\xe1lisis de Sentimiento"),(0,t.kt)("p",null,"El an\xe1lisis de sentimiento es la tarea de clasificar el texto en sentimientos positivos, negativos u otros."),(0,t.kt)("h4",{id:"modelo-vs-ai-vs-llm"},'"Modelo" vs. "AI" vs. "LLM"'),(0,t.kt)("p",null,'Estos t\xe9rminos se utilizan de manera algo intercambiable a lo largo de este curso, pero no siempre significan lo mismo. Los LLM son un tipo de AI, como se se\xf1al\xf3 anteriormente, pero no todas las AIs son LLM. Cuando mencionamos modelos en este curso, nos referimos a modelos de IA. Como tal, en este curso, puede considerar los t\xe9rminos "modelo" y "IA" como intercambiables.'),(0,t.kt)("h4",{id:"verbalizador"},"Verbalizador"),(0,t.kt)("p",null,"En el entorno de clasificaci\xf3n, los verbalizadores son mapeos de etiquetas a palabras en el vocabulario del modelo de lenguaje",(0,t.kt)("sup",{parentName:"p",id:"fnref-2"},(0,t.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),". Por ejemplo, considere realizar la clasificaci\xf3n de sentimientos con el siguiente prompt:"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-text"},"Tweet: \"Amo los hotpockets\"\n\xbfCu\xe1l es el sentimiento de este tweet? Diga 'pos' o 'neg'.\n")),(0,t.kt)("p",null,"Aqu\xed, el verbalizador es el mapeo de las etiquetas conceptuales de ",(0,t.kt)("inlineCode",{parentName:"p"},"positive")," y ",(0,t.kt)("inlineCode",{parentName:"p"},"negative")," a los tokens ",(0,t.kt)("inlineCode",{parentName:"p"},"pos")," y ",(0,t.kt)("inlineCode",{parentName:"p"},"neg"),"."),(0,t.kt)("h4",{id:"reinforcement-learning-from-human-feedback-rlhf"},"Reinforcement Learning from Human Feedback (RLHF)"),(0,t.kt)("p",null,"RLHF es un m\xe9todo para ajustar los LLM seg\xfan los datos de preferencia humana."),(0,t.kt)("div",{className:"footnotes"},(0,t.kt)("hr",{parentName:"div"}),(0,t.kt)("ol",{parentName:"div"},(0,t.kt)("li",{parentName:"ol",id:"fn-1"},"Branch, H. J., Cefalu, J. R., McHugh, J., Hujer, L., Bahl, A., del Castillo Iglesias, D., Heichman, R., & Darwishi, R. (2022). Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples.\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,t.kt)("li",{parentName:"ol",id:"fn-2"},"Schick, T., & Sch\xfctze, H. (2020). Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.\n",(0,t.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}p.isMDXComponent=!0}}]);