"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[8846],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>f});var o=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=o.createContext({}),p=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=p(e.components);return o.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},u=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),c=p(n),u=r,f=c["".concat(l,".").concat(u)]||c[u]||d[u]||a;return n?o.createElement(f,s(s({ref:t},m),{},{components:n})):o.createElement(f,s({ref:t},m))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,s=new Array(a);s[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[c]="string"==typeof e?e:r,s[1]=i;for(var p=2;p<a;p++)s[p]=n[p];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}u.displayName="MDXCreateElement"},88961:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>l,toc:()=>m});var o=n(87462),r=(n(67294),n(3905));const a=n.p+"assets/images/prompt_tuning-6a04ae02ae3666c98fd9f1c5e9131d34.webp",s={sidebar_position:1},i="\ud83d\udd34 Soft Prompts",l={unversionedId:"trainable/soft_prompting",id:"trainable/soft_prompting",title:"\ud83d\udd34 Soft Prompts",description:"La sintonizaci\xf3n de prompts (@lester2021power), una alternativa a la sintonizaci\xf3n fina del modelo (@khashabi2021prompt), congela los pesos del modelo y actualiza los par\xe1metros de un prompt. El prompt resultante es un 'prompt suave'.",source:"@site/i18n/es/docusaurus-plugin-content-docs/current/trainable/soft_prompting.md",sourceDirName:"trainable",slug:"/trainable/soft_prompting",permalink:"/es/docs/trainable/soft_prompting",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/trainable/soft_prompting.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udcaa Prompt Tuning",permalink:"/es/docs/category/-prompt-tuning"},next:{title:"\ud83d\udd34 Soft Prompts Interpretables",permalink:"/es/docs/trainable/discretized"}},p={},m=[{value:"C\xf3mo funciona",id:"c\xf3mo-funciona",level:2}],c={toc:m},d="wrapper";function u(e){let{components:t,...n}=e;return(0,r.kt)(d,(0,o.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"-soft-prompts"},"\ud83d\udd34 Soft Prompts"),(0,r.kt)("p",null,"La sintonizaci\xf3n de prompts",(0,r.kt)("sup",{parentName:"p",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),", una alternativa a la sintonizaci\xf3n fina del modelo",(0,r.kt)("sup",{parentName:"p",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),", congela los pesos del modelo y actualiza los par\xe1metros de un prompt. El prompt resultante es un 'prompt suave'."),(0,r.kt)("div",{style:{textAlign:"center"}},(0,r.kt)("img",{src:a,style:{width:"500px"}})),(0,r.kt)("div",{style:{textAlign:"center"}},"Ajuste del modelo vs. Ajuste del prompt (Lester et al.)"),(0,r.kt)("p",null,"La imagen anterior contrasta la sintonizaci\xf3n del modelo con la sintonizaci\xf3n del prompt. En la sintonizaci\xf3n del modelo, se ajusta el mismo modelo en diferentes tareas. Esto te da unos pocos modelos diferentes, con los cuales no necesariamente puedes agrupar f\xe1cilmente las entradas."),(0,r.kt)("p",null,"Por otro lado, la sintonizaci\xf3n del prompt te permite utilizar el mismo modelo para todas las tareas. S\xf3lo necesitas a\xf1adir los prompts adecuados en el momento de la inferencia, lo que facilita el agrupamiento de diferentes tareas. B\xe1sicamente, esto es la misma ventaja que tiene la sintonizaci\xf3n regular de prompts. Adem\xe1s, los prompts suaves entrenados para un solo modelo en m\xfaltiples tareas a menudo tendr\xe1n la misma longitud de tokens."),(0,r.kt)("h2",{id:"c\xf3mo-funciona"},"C\xf3mo funciona"),(0,r.kt)("p",null,"Para entender la l\xf3gica b\xe1sica detr\xe1s de la sintonizaci\xf3n suave del prompt, pensemos en c\xf3mo funciona la ",(0,r.kt)("strong",{parentName:"p"},"inferencia del modelo"),' en un prompt dado: "\xbfCu\xe1nto es 2+2?".'),(0,r.kt)("p",null,"1) Podr\xeda ser tokenizado como \"\xbfCu\xe1nto, 'es', 2, +, 2,?\". "),(0,r.kt)("p",null,"2) Luego, cada token se convertir\xe1 en un vector de valores."),(0,r.kt)("p",null,"3) Estos vectores de valores pueden considerarse como par\xe1metros del modelo. El modelo puede ser adicionalmente entrenado, ajustando s\xf3lo los pesos de estos prompts."),(0,r.kt)("p",null,"N\xf3tese que tan pronto como empezamos a actualizar estos pesos, los vectores de los tokens ya no corresponden a los embeddings reales del vocabulario."),(0,r.kt)("h1",{id:"resultados"},"Resultados"),(0,r.kt)("p",null,"La sintonizaci\xf3n de prompts funciona mejor con modelos m\xe1s grandes. Los modelos m\xe1s grandes tambi\xe9n requieren menos tokens suaves del prompt. Sin embargo, m\xe1s de 20 tokens no produce ganancias significativas de rendimiento."),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"Lester, B., Al-Rfou, R., & Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Khashabi, D., Lyu, S., Min, S., Qin, L., Richardson, K., Welleck, S., Hajishirzi, H., Khot, T., Sabharwal, A., Singh, S., & Choi, Y. (2021). Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}u.isMDXComponent=!0}}]);