"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[6708],{3905:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>g});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function i(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?i(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function s(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=t.createContext({}),m=function(e){var a=t.useContext(l),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},p=function(e){var a=m(e.components);return t.createElement(l.Provider,{value:a},e.children)},f="mdxType",u={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},d=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),f=m(n),d=r,g=f["".concat(l,".").concat(d)]||f[d]||u[d]||i;return n?t.createElement(g,o(o({ref:a},p),{},{components:n})):t.createElement(g,o({ref:a},p))}));function g(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[f]="string"==typeof e?e:r,o[1]=s;for(var m=2;m<i;m++)o[m]=n[m];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}d.displayName="MDXCreateElement"},98343:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>m});var t=n(87462),r=(n(67294),n(3905));const i={sidebar_position:1e3},o="Daftar Pustaka",s={unversionedId:"bibliography",id:"bibliography",title:"Daftar Pustaka",description:"Halaman ini berisi daftar terorganisir dari semua makalah yang digunakan oleh kursus ini. Makalah-makalah tersebut diatur berdasarkan topik.",source:"@site/i18n/id/docusaurus-plugin-content-docs/current/bibliography.md",sourceDirName:".",slug:"/bibliography",permalink:"/id/docs/bibliography",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/bibliography.md",tags:[],version:"current",sidebarPosition:1e3,frontMatter:{sidebar_position:1e3},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udcd9 Referensi Kosakata",permalink:"/id/docs/vocabulary"},next:{title:"\ud83d\udce6 Prompted Products",permalink:"/id/docs/products"}},l={},m=[{value:"Agen",id:"agen",level:2},{value:"MRKL(@karpas2022mrkl)",id:"mrklkarpas2022mrkl",level:4},{value:"ReAct(@yao2022react)",id:"reactyao2022react",level:4},{value:"PAL(@gao2022pal)",id:"palgao2022pal",level:4},{value:"Auto-GPT(@richards2023)",id:"auto-gptrichards2023",level:4},{value:"Baby AGI(@nakajima2023)",id:"baby-aginakajima2023",level:4},{value:"AgentGPT(@reworkd2023)",id:"agentgptreworkd2023",level:4},{value:"Toolformer(@schick2023toolformer)",id:"toolformerschick2023toolformer",level:4},{value:"Otomatisasi",id:"otomatisasi",level:2},{value:"AutoPrompt: Mengumpulkan Pengetahuan dari Model Bahasa dengan Prompts yang Dibuat Secara Otomatis(@shin2020autoprompt)",id:"autoprompt-mengumpulkan-pengetahuan-dari-model-bahasa-dengan-prompts-yang-dibuat-secara-otomatisshin2020autoprompt",level:4},{value:"automatic prompt engineer(@zhou2022large)",id:"automatic-prompt-engineerzhou2022large",level:4},{value:"Soft Prompting(@lester2021power)",id:"soft-promptinglester2021power",level:4},{value:"discretized soft prompting (interpreting)(@khashabi2021prompt)",id:"discretized-soft-prompting-interpretingkhashabi2021prompt",level:4},{value:"Dataset",id:"dataset",level:2},{value:"SCAN dataset (compositional generalization)(@lake2018scan)",id:"scan-dataset-compositional-generalizationlake2018scan",level:4},{value:"GSM8K(@cobbe2021training)",id:"gsm8kcobbe2021training",level:4},{value:"hotpotQA(@yang2018hotpotqa)",id:"hotpotqayang2018hotpotqa",level:4},{value:"multiarith(@roy-roth-2015-solving)",id:"multiarithroy-roth-2015-solving",level:4},{value:"fever dataset(@thorne2018fever)",id:"fever-datasetthorne2018fever",level:4},{value:"bbq(@parrish2021bbq)",id:"bbqparrish2021bbq",level:4},{value:"Pendeteksi",id:"pendeteksi",level:2},{value:"Jangan melarang chatgpt di sekolah. mengajar dengan chatgpt.(@roose2022dont)",id:"jangan-melarang-chatgpt-di-sekolah-mengajar-dengan-chatgptroose2022dont",level:4},{value:"Sekolah-sekolah Sebaiknya Tidak Melarang Akses ke ChatGPT (@lipman2022gpt)",id:"sekolah-sekolah-sebaiknya-tidak-melarang-akses-ke-chatgpt-lipman2022gpt",level:4},{value:"Certified Neural Network Watermarks with Randomized Smoothing(@bansal2022certified)",id:"certified-neural-network-watermarks-with-randomized-smoothingbansal2022certified",level:4},{value:"Watermarking Pre-trained Language Models dengan Backdooring(@gu2022watermarking)",id:"watermarking-pre-trained-language-models-dengan-backdooringgu2022watermarking",level:4},{value:"GW menyiapkan respons disiplin terhadap program AI saat fakultas menjelajahi penggunaan pendidikan (@noonan2023gw)",id:"gw-menyiapkan-respons-disiplin-terhadap-program-ai-saat-fakultas-menjelajahi-penggunaan-pendidikan-noonan2023gw",level:4},{value:"A Watermark for Large Language Models(@kirchenbauer2023watermarking)",id:"a-watermark-for-large-language-modelskirchenbauer2023watermarking",level:4},{value:"DetectGPT: Deteksi Teks yang Dibuat oleh Mesin &#39;Zero-Shot&#39; dengan Menggunakan Probabilitas Kurva (@mitchell2023detectgpt)",id:"detectgpt-deteksi-teks-yang-dibuat-oleh-mesin-zero-shot-dengan-menggunakan-probabilitas-kurva-mitchell2023detectgpt",level:4},{value:"Prompt Engineering untuk Gambar",id:"prompt-engineering-untuk-gambar",level:2},{value:"Prompt Engineering for Text-Based Generative Art(@oppenlaender2022prompt)",id:"prompt-engineering-for-text-based-generative-artoppenlaender2022prompt",level:4},{value:"The DALLE 2 Prompt Book(@parsons2022dalleprompt)",id:"the-dalle-2-prompt-bookparsons2022dalleprompt",level:4},{value:"With the right prompt, Stable Diffusion 2.0 can do hands.(@blake2022with)",id:"with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with",level:4},{value:"Serba Aneka",id:"serba-aneka",level:2},{value:"The Turking Test: Can Language Models Understand Instructions?(@efrat2020turking)",id:"the-turking-test-can-language-models-understand-instructionsefrat2020turking",level:4},{value:"Taksonomi Pengubah Prompt untuk Menghasilkan Text-To-Image (@oppenlaender2022taxonomy)",id:"taksonomi-pengubah-prompt-untuk-menghasilkan-text-to-image-oppenlaender2022taxonomy",level:4},{value:"DiffusionDB: Dataset Galeri Prompt Skala Besar untuk Model Generatif Text-To-Image (@wang2022diffusiondb)",id:"diffusiondb-dataset-galeri-prompt-skala-besar-untuk-model-generatif-text-to-image-wang2022diffusiondb",level:4},{value:"Optimizing Prompts for Text-to-Image Generation(@hao2022optimizing)",id:"optimizing-prompts-for-text-to-image-generationhao2022optimizing",level:4},{value:"Language Model Cascades(@dohan2022language)",id:"language-model-cascadesdohan2022language",level:4},{value:"Design Guidelines for Prompt Engineering Text-to-Image Generative Models(@liu2022design)",id:"design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design",level:4},{value:"Discovering Language Model Behaviors with Model-Written Evaluations(@perez2022discovering)",id:"discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering",level:4},{value:"Selective Annotation Makes Language Models Better Few-Shot Learners(@su2022selective)",id:"selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective",level:4},{value:"Atlas: Few-shot Learning with Retrieval Augmented Language Models(@izacard2022atlas)",id:"atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas",level:4},{value:"STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension(@wang2022strudel)",id:"strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel",level:4},{value:"Prompting Is Programming: A Query Language For Large Language Models(@beurerkellner2022prompting)",id:"prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting",level:4},{value:"Parallel Context Windows Improve In-Context Learning of Large Language Models(@ratner2022parallel)",id:"parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel",level:4},{value:"Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models(@bursztyn2022learning)",id:"learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning",level:4},{value:"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks(@wang2022supernaturalinstructions)",id:"super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions",level:4},{value:"Making Pre-trained Language Models Better Few-shot Learners(@gao2021making)",id:"making-pre-trained-language-models-better-few-shot-learnersgao2021making",level:4},{value:"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models(@dang2022prompt)",id:"how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt",level:4},{value:"On Measuring Social Biases in Prompt-Based Multi-Task Learning(@akyrek2022measuring)",id:"on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring",level:4},{value:"Plot Writing From Pre-Trained Language Models(@jin2022plot)",id:"plot-writing-from-pre-trained-language-modelsjin2022plot",level:4},{value:"{S}tereo{S}et: Mengukur bias stereotip dalam model bahasa terlatih sebelumnya (@nadeem-etal-2021-stereoset)",id:"stereoset-mengukur-bias-stereotip-dalam-model-bahasa-terlatih-sebelumnya-nadeem-etal-2021-stereoset",level:4},{value:"Survey of Hallucination in Natural Language Generation(@Ji_2022)",id:"survey-of-hallucination-in-natural-language-generationji_2022",level:4},{value:"Wordcraft: Menulis Cerita dengan Model Bahasa Besar (@yuan2022wordcraft)",id:"wordcraft-menulis-cerita-dengan-model-bahasa-besar-yuan2022wordcraft",level:4},{value:"PainPoints: Sebuah Kerangka Kerja untuk Deteksi Nyeri Kronis berbasis Bahasa dan Ringkasan Teks Kolaboratif Ahli (@fadnavis2022pain)",id:"painpoints-sebuah-kerangka-kerja-untuk-deteksi-nyeri-kronis-berbasis-bahasa-dan-ringkasan-teks-kolaboratif-ahli-fadnavis2022pain",level:4},{value:"Self-Instruct: Aligning Language Model with Self Generated Instructions(@wang2022selfinstruct)",id:"self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct",level:4},{value:"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models(@guo2022images)",id:"from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images",level:4},{value:"New and improved content moderation tooling(@markov_2022)",id:"new-and-improved-content-moderation-toolingmarkov_2022",level:4},{value:"No title(@openai_api)",id:"no-titleopenai_api",level:4},{value:"Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference(@schick2020exploiting)",id:"exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting",level:4},{value:"Pembelajaran konsep level manusia melalui induksi program probabilistik (@lake2015human)",id:"pembelajaran-konsep-level-manusia-melalui-induksi-program-probabilistik-lake2015human",level:4},{value:"{Riffusion - Stable diffusion for real-time music generation}(@Forsgren_Martiros_2022)",id:"riffusion---stable-diffusion-for-real-time-music-generationforsgren_martiros_2022",level:4},{value:"Cara menggunakan ChatGPT dari OpenAI untuk menulis cold email yang sempurna (@bonta2022how)",id:"cara-menggunakan-chatgpt-dari-openai-untuk-menulis-cold-email-yang-sempurna-bonta2022how",level:4},{value:"Cacti: biology and uses(@nobel2002cacti)",id:"cacti-biology-and-usesnobel2002cacti",level:4},{value:"Apakah Model Bahasa Lebih Buruk daripada Manusia dalam Mengikuti Petunjuk? Ini Rumit (@webson2023itscomplicated)",id:"apakah-model-bahasa-lebih-buruk-daripada-manusia-dalam-mengikuti-petunjuk-ini-rumit-webson2023itscomplicated",level:4},{value:"Mengungkap Kebersamaan Kognitif dalam Model Bahasa Besar: Agen Penyelesaian Tugas melalui Kolaborasi Diri Multi-Persona (@wang2023unleashing)",id:"mengungkap-kebersamaan-kognitif-dalam-model-bahasa-besar-agen-penyelesaian-tugas-melalui-kolaborasi-diri-multi-persona-wang2023unleashing",level:4},{value:"Prompt Hacking",id:"prompt-hacking",level:2},{value:"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods(@crothers2022machine)",id:"machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine",level:4},{value:"Jebol baru berdasarkan fungsi virtual - menyelundupkan token ilegal ke backend.(@nin2023new)",id:"jebol-baru-berdasarkan-fungsi-virtual---menyelundupkan-token-ilegal-ke-backendnin2023new",level:4},{value:"Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks(@kang2023exploiting)",id:"exploiting-programmatic-behavior-of-llms-dual-use-through-standard-security-attackskang2023exploiting",level:4},{value:"More than you&#39;ve asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models(@greshake2023youve)",id:"more-than-youve-asked-for-a-comprehensive-analysis-of-novel-prompt-injection-threats-to-application-integrated-large-language-modelsgreshake2023youve",level:4},{value:"ChatGPT &quot;DAN&quot; (and other &quot;Jailbreaks&quot;)(@kiho2023chatgpt)",id:"chatgpt-dan-and-other-jailbreakskiho2023chatgpt",level:4},{value:"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples(@branch2022evaluating)",id:"evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating",level:4},{value:"Prompt injection attacks against GPT-3(@simon2022inject)",id:"prompt-injection-attacks-against-gpt-3simon2022inject",level:4},{value:"Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions(@goodside2022inject)",id:"exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject",level:4},{value:"History Correction(@goodside2022history)",id:"history-correctiongoodside2022history",level:4},{value:"adversarial-prompts(@chase2021adversarial)",id:"adversarial-promptschase2021adversarial",level:4},{value:"GPT-3 Prompt Injection Defenses(@goodside2021gpt)",id:"gpt-3-prompt-injection-defensesgoodside2021gpt",level:4},{value:"Talking to machines: prompt engineering &amp; injection(@christoph2022talking)",id:"talking-to-machines-prompt-engineering--injectionchristoph2022talking",level:4},{value:"Using GPT-Eliezer against ChatGPT Jailbreaking(@armstrong2022using)",id:"using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using",level:4},{value:"Exploring Prompt Injection Attacks(@selvi2022exploring)",id:"exploring-prompt-injection-attacksselvi2022exploring",level:4},{value:"Seluruh permintaan Bing Chat Microsoft?! (Halo, Sydney.)(@kevinbing)",id:"seluruh-permintaan-bing-chat-microsoft-halo-sydneykevinbing",level:4},{value:"Ignore Previous Prompt: Attack Techniques For Language Models(@perez2022jailbreak)",id:"ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak",level:4},{value:"Lessons learned on Language Model Safety and misuse(@brundage_2022)",id:"lessons-learned-on-language-model-safety-and-misusebrundage_2022",level:4},{value:"Toxicity Detection with Generative Prompt-based Inference(@wang2022jailbreak)",id:"toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak",level:4},{value:"ok saya melihat beberapa orang membobol perlindungan yang diberikan oleh openai pada chatgpt, jadi saya harus mencobanya sendiri (@alice2022jailbreak)",id:"ok-saya-melihat-beberapa-orang-membobol-perlindungan-yang-diberikan-oleh-openai-pada-chatgpt-jadi-saya-harus-mencobanya-sendiri-alice2022jailbreak",level:4},{value:"Melewati upaya penyelarasan ChatGPT @OpenAI dengan trik aneh ini (@miguel2022jailbreak)",id:"melewati-upaya-penyelarasan-chatgpt-openai-dengan-trik-aneh-ini-miguel2022jailbreak",level:4},{value:"ChatGPT membobol dirinya sendiri (@derek2022jailbreak)",id:"chatgpt-membobol-dirinya-sendiri-derek2022jailbreak",level:4},{value:"Menggunakan &quot;pretend&quot; di #ChatGPT bisa melakukan beberapa hal yang luar biasa. Anda dapat sedikit mendapatkan wawasan tentang masa depan, alam semesta alternatif. (@nero2022jailbreak)",id:"menggunakan-pretend-di-chatgpt-bisa-melakukan-beberapa-hal-yang-luar-biasa-anda-dapat-sedikit-mendapatkan-wawasan-tentang-masa-depan-alam-semesta-alternatif-nero2022jailbreak",level:4},{value:"Aku agak lebih suka yang ini, bahkan lebih! (@nick2022jailbreak)",id:"aku-agak-lebih-suka-yang-ini-bahkan-lebih-nick2022jailbreak",level:4},{value:"uh oh(@sam2022jailbreak)",id:"uh-ohsam2022jailbreak",level:4},{value:"Membangun Mesin Virtual di dalam ChatGPT (@jonas2022jailbreak)",id:"membangun-mesin-virtual-di-dalam-chatgpt-jonas2022jailbreak",level:4},{value:"Keandalan",id:"keandalan",level:2},{value:"MathPrompter: Reasoning Matematika menggunakan Model Bahasa Besar (@imani2023mathprompter)",id:"mathprompter-reasoning-matematika-menggunakan-model-bahasa-besar-imani2023mathprompter",level:4},{value:"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning(@ye2022unreliability)",id:"the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability",level:4},{value:"Prompting GPT-3 To Be Reliable(@si2022prompting)",id:"prompting-gpt-3-to-be-reliablesi2022prompting",level:4},{value:"Pada Kemajuan dalam Meningkatkan Model Bahasa Sebagai Pemikir yang Lebih Baik (@li2022advance)",id:"pada-kemajuan-dalam-meningkatkan-model-bahasa-sebagai-pemikir-yang-lebih-baik-li2022advance",level:4},{value:"Tanyakan Apa Saja pada Saya: Sebuah strategi sederhana untuk memicu model bahasa (@arora2022ama)",id:"tanyakan-apa-saja-pada-saya-sebuah-strategi-sederhana-untuk-memicu-model-bahasa-arora2022ama",level:4},{value:"Calibrate Before Use: Improving Few-Shot Performance of Language Models(@zhao2021calibrate)",id:"calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate",level:4},{value:"Apakah model bahasa besar dapat melakukan penalaran tentang pertanyaan medis?(@livin2022large)",id:"apakah-model-bahasa-besar-dapat-melakukan-penalaran-tentang-pertanyaan-medislivin2022large",level:4},{value:"Meningkatkan Konsistensi Diri dan Performa dari Model Bahasa Pra-terlatih melalui Inferensi Bahasa Alami (@mitchell2022enhancing)",id:"meningkatkan-konsistensi-diri-dan-performa-dari-model-bahasa-pra-terlatih-melalui-inferensi-bahasa-alami-mitchell2022enhancing",level:4},{value:"Kalau Dipikir-pikir Lagi, Mari Kita Tidak Berpikir Langkah demi Langkah! Bias dan Toxicity pda Zero-Shot Reasoning(@shaikh2022second)",id:"kalau-dipikir-pikir-lagi-mari-kita-tidak-berpikir-langkah-demi-langkah-bias-dan-toxicity-pda-zero-shot-reasoningshaikh2022second",level:4},{value:"Mengevaluasi model bahasa bisa saja sulit(@chase2022evaluating)",id:"mengevaluasi-model-bahasa-bisa-saja-sulitchase2022evaluating",level:4},{value:"Survey",id:"survey",level:2},{value:"Speech and Language Processing: Pengantar Pemrosesan Bahasa Alami, Linguistik Komputasional, dan Pengenalan Suara (@jurafsky2009)",id:"speech-and-language-processing-pengantar-pemrosesan-bahasa-alami-linguistik-komputasional-dan-pengenalan-suara-jurafsky2009",level:4},{value:"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing(@liu2021pretrain)",id:"pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain",level:4},{value:"PromptPapers(@ning2022papers)",id:"promptpapersning2022papers",level:4},{value:"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT(@white2023prompt)",id:"a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt",level:4},{value:"Teknik",id:"teknik",level:2},{value:"Chain of Thought Prompting Penalaran dalam Model Bahasa Besar (@wei2022chain)",id:"chain-of-thought-prompting-penalaran-dalam-model-bahasa-besar-wei2022chain",level:4},{value:"Large Language Model adalah Zero-Shot Reasoners(@kojima2022large)",id:"large-language-model-adalah-zero-shot-reasonerskojima2022large",level:4},{value:"Ketetapan Diri Meningkatkan Rantai Berpikir Penalaran pada Model Bahasa (@wang2022selfconsistency)",id:"ketetapan-diri-meningkatkan-rantai-berpikir-penalaran-pada-model-bahasa-wang2022selfconsistency",level:4},{value:"What Makes Good In-Context Examples for GPT-3?(@liu2021makes)",id:"what-makes-good-in-context-examples-for-gpt-3liu2021makes",level:4},{value:"Prompt Pengetahuan yang Dihasilkan untuk Penalaran Wajar (@liu2021generated)",id:"prompt-pengetahuan-yang-dihasilkan-untuk-penalaran-wajar-liu2021generated",level:4},{value:"Recitation-Augmented Language Models(@sun2022recitationaugmented)",id:"recitation-augmented-language-modelssun2022recitationaugmented",level:4},{value:"Mempertimbangkan Kembali Peran Demonstrasi: Apa yang Membuat Pembelajaran Kontekstual Bekerja?(@min2022rethinking)",id:"mempertimbangkan-kembali-peran-demonstrasi-apa-yang-membuat-pembelajaran-kontekstual-bekerjamin2022rethinking",level:4},{value:"Tunjukkan Pekerjaan Anda: Scratchpads untuk Komputasi Menengah dengan Model Bahasa (@nye2021work)",id:"tunjukkan-pekerjaan-anda-scratchpads-untuk-komputasi-menengah-dengan-model-bahasa-nye2021work",level:4},{value:"Maieutic Prompting: Penalaran yang Logis dan Konsisten dengan Penjelasan Rekursif (@jung2022maieutic)",id:"maieutic-prompting-penalaran-yang-logis-dan-konsisten-dengan-penjelasan-rekursif-jung2022maieutic",level:4},{value:"STaR: Memulai Penalaran Dengan Penalaran(@zelikman2022star)",id:"star-memulai-penalaran-dengan-penalaranzelikman2022star",level:4},{value:"Prompt Least-to-Most Memungkinkan Pemikiran Kompleks dalam Model Bahasa Besar (@zhou2022leasttomost)",id:"prompt-least-to-most-memungkinkan-pemikiran-kompleks-dalam-model-bahasa-besar-zhou2022leasttomost",level:4},{value:"Reframing Instructional Prompts to GPTk\u2019s Language(@mishra2022reframing)",id:"reframing-instructional-prompts-to-gptks-languagemishra2022reframing",level:4},{value:"Memangkas Prompt dan Parameter: Pembelajaran Few-Shot Sederhana dengan Model Bahasa (@logan-iv-etal-2022-cutting)",id:"memangkas-prompt-dan-parameter-pembelajaran-few-shot-sederhana-dengan-model-bahasa-logan-iv-etal-2022-cutting",level:4},{value:"Role-Play dengan Model Bahasa Besar (@shanahan2023roleplay)",id:"role-play-dengan-model-bahasa-besar-shanahan2023roleplay",level:4},{value:"CAMEL: Agen Komunikatif untuk &quot;Eksplorasi&quot; Pikiran Masyarakat Model Bahasa Skala Besar (@li2023camel)",id:"camel-agen-komunikatif-untuk-eksplorasi-pikiran-masyarakat-model-bahasa-skala-besar-li2023camel",level:4},{value:"TELeR: Taksonomi Umum dari LLM Prompts untuk Benchmarking Tugas Kompleks (@santu2023teler)",id:"teler-taksonomi-umum-dari-llm-prompts-untuk-benchmarking-tugas-kompleks-santu2023teler",level:4},{value:"Model",id:"model",level:2},{value:"Model Gambar",id:"model-gambar",level:3},{value:"Stable Diffusion(@rombach2021highresolution)",id:"stable-diffusionrombach2021highresolution",level:4},{value:"DALLE(@ramesh2022hierarchical)",id:"dalleramesh2022hierarchical",level:4},{value:"Model Bahasa",id:"model-bahasa",level:3},{value:"ChatGPT(@chatgpt2022)",id:"chatgptchatgpt2022",level:4},{value:"GPT-3(@brown2020language)",id:"gpt-3brown2020language",level:4},{value:"Instruct GPT(@ouyang2022training)",id:"instruct-gptouyang2022training",level:4},{value:"GPT-4(@openai2023gpt4)",id:"gpt-4openai2023gpt4",level:4},{value:"PaLM: Memperbesar Pembentukan Bahasa dengan Pathways(@chowdhery2022palm)",id:"palm-memperbesar-pembentukan-bahasa-dengan-pathwayschowdhery2022palm",level:4},{value:"BLOOM: Sebuah Model Bahasa Multilingual Open-Access dengan 176B Parameter (@scao2022bloom)",id:"bloom-sebuah-model-bahasa-multilingual-open-access-dengan-176b-parameter-scao2022bloom",level:4},{value:"BLOOM+1: Menambahkan Dukungan Bahasa ke BLOOM untuk Prompt Zero-Shot (@yong2022bloom1)",id:"bloom1-menambahkan-dukungan-bahasa-ke-bloom-untuk-prompt-zero-shot-yong2022bloom1",level:4},{value:"Jurassic-1: Detail Teknis dan Evaluasi, White paper, AI21 Labs, 2021(@lieberjurassic)",id:"jurassic-1-detail-teknis-dan-evaluasi-white-paper-ai21-labs-2021lieberjurassic",level:4},{value:"GPT-J-6B: Sebuah Model Bahasa Autoregresif dengan 6 Miliar Parameter (@wange2021gptj)",id:"gpt-j-6b-sebuah-model-bahasa-autoregresif-dengan-6-miliar-parameter-wange2021gptj",level:4},{value:"Roberta: Pendekatan pra-pelatihan bert yang dioptimalkan secara kuat (@liu2019roberta)",id:"roberta-pendekatan-pra-pelatihan-bert-yang-dioptimalkan-secara-kuat-liu2019roberta",level:4},{value:"Tooling",id:"tooling",level:2},{value:"Ides",id:"ides",level:3},{value:"TextBox 2.0: A Text Generation Library with Pre-trained Language Models(@tang2022textbox)",id:"textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox",level:4},{value:"Prompt Engineering Interaktif dan Visual untuk Adaptasi Tugas Ad-hoc dengan Model Bahasa Besar (@strobelt2022promptide)",id:"prompt-engineering-interaktif-dan-visual-untuk-adaptasi-tugas-ad-hoc-dengan-model-bahasa-besar-strobelt2022promptide",level:4},{value:"PromptSource: Lingkungan Pengembangan Terpadu dan Repositori untuk Promp Bahasa Alami (@bach2022promptsource)",id:"promptsource-lingkungan-pengembangan-terpadu-dan-repositori-untuk-promp-bahasa-alami-bach2022promptsource",level:4},{value:"PromptChainer: Menghubungkan Prompt Model Bahasa yang Besar melalui Pemrograman Visual(@wu2022promptchainer)",id:"promptchainer-menghubungkan-prompt-model-bahasa-yang-besar-melalui-pemrograman-visualwu2022promptchainer",level:4},{value:"OpenPrompt: An Open-source Framework for Prompt-learning(@ding2021openprompt)",id:"openprompt-an-open-source-framework-for-prompt-learningding2021openprompt",level:4},{value:"PromptMaker: Prompt-Based Prototyping dengan Large\xa0Language\xa0Models(@jiang2022promptmaker)",id:"promptmaker-prompt-based-prototyping-dengan-largelanguagemodelsjiang2022promptmaker",level:4},{value:"Tools",id:"tools",level:3},{value:"LangChain(@Chase_LangChain_2022)",id:"langchainchase_langchain_2022",level:4},{value:"GPT Index(@Liu_GPT_Index_2022)",id:"gpt-indexliu_gpt_index_2022",level:4}],p={toc:m},f="wrapper";function u(e){let{components:a,...n}=e;return(0,r.kt)(f,(0,t.Z)({},p,n,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"daftar-pustaka"},"Daftar Pustaka"),(0,r.kt)("p",null,"Halaman ini berisi daftar terorganisir dari semua makalah yang digunakan oleh kursus ini. Makalah-makalah tersebut diatur berdasarkan topik."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Untuk mengutip kursus ini, gunakan kutipan yang disediakan di repositori Github.")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-md"},"@software{Schulhoff_Learn_Prompting_2022,\n    author = {Schulhoff, Sander and Community Contributors},\n    month = dec,\n    title = {{Learn Prompting}},\n    url = {https://github.com/trigaten/Learn_Prompting},\n    year = {2022}\n}\n")),(0,r.kt)("p",null,"Catatan: ",(0,r.kt)("a",{parentName:"p",href:"https://twitter.com/janleike/status/1584618242756132864"},"karena baik GPT-3 maupun GPT-3 Instruct paper tidak sesuai dengan model davinci"),", saya berusaha untuk tidak mengutipnya sebagai model tersebut."),(0,r.kt)("h2",{id:"agen"},"Agen"),(0,r.kt)("h4",{id:"mrklkarpas2022mrkl"},"MRKL",(0,r.kt)("sup",{parentName:"h4",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))),(0,r.kt)("h4",{id:"reactyao2022react"},"ReAct",(0,r.kt)("sup",{parentName:"h4",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2"))),(0,r.kt)("h4",{id:"palgao2022pal"},"PAL",(0,r.kt)("sup",{parentName:"h4",id:"fnref-3"},(0,r.kt)("a",{parentName:"sup",href:"#fn-3",className:"footnote-ref"},"3"))),(0,r.kt)("h4",{id:"auto-gptrichards2023"},"Auto-GPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-4"},(0,r.kt)("a",{parentName:"sup",href:"#fn-4",className:"footnote-ref"},"4"))),(0,r.kt)("h4",{id:"baby-aginakajima2023"},"Baby AGI",(0,r.kt)("sup",{parentName:"h4",id:"fnref-5"},(0,r.kt)("a",{parentName:"sup",href:"#fn-5",className:"footnote-ref"},"5"))),(0,r.kt)("h4",{id:"agentgptreworkd2023"},"AgentGPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-6"},(0,r.kt)("a",{parentName:"sup",href:"#fn-6",className:"footnote-ref"},"6"))),(0,r.kt)("h4",{id:"toolformerschick2023toolformer"},"Toolformer",(0,r.kt)("sup",{parentName:"h4",id:"fnref-7"},(0,r.kt)("a",{parentName:"sup",href:"#fn-7",className:"footnote-ref"},"7"))),(0,r.kt)("h2",{id:"otomatisasi"},"Otomatisasi"),(0,r.kt)("h4",{id:"autoprompt-mengumpulkan-pengetahuan-dari-model-bahasa-dengan-prompts-yang-dibuat-secara-otomatisshin2020autoprompt"},"AutoPrompt: Mengumpulkan Pengetahuan dari Model Bahasa dengan Prompts yang Dibuat Secara Otomatis",(0,r.kt)("sup",{parentName:"h4",id:"fnref-8"},(0,r.kt)("a",{parentName:"sup",href:"#fn-8",className:"footnote-ref"},"8"))),(0,r.kt)("h4",{id:"automatic-prompt-engineerzhou2022large"},"automatic prompt engineer",(0,r.kt)("sup",{parentName:"h4",id:"fnref-9"},(0,r.kt)("a",{parentName:"sup",href:"#fn-9",className:"footnote-ref"},"9"))),(0,r.kt)("h4",{id:"soft-promptinglester2021power"},"Soft Prompting",(0,r.kt)("sup",{parentName:"h4",id:"fnref-10"},(0,r.kt)("a",{parentName:"sup",href:"#fn-10",className:"footnote-ref"},"10"))),(0,r.kt)("h4",{id:"discretized-soft-prompting-interpretingkhashabi2021prompt"},"discretized soft prompting (interpreting)",(0,r.kt)("sup",{parentName:"h4",id:"fnref-11"},(0,r.kt)("a",{parentName:"sup",href:"#fn-11",className:"footnote-ref"},"11"))),(0,r.kt)("h2",{id:"dataset"},"Dataset"),(0,r.kt)("h4",{id:"scan-dataset-compositional-generalizationlake2018scan"},"SCAN dataset (compositional generalization)",(0,r.kt)("sup",{parentName:"h4",id:"fnref-12"},(0,r.kt)("a",{parentName:"sup",href:"#fn-12",className:"footnote-ref"},"12"))),(0,r.kt)("h4",{id:"gsm8kcobbe2021training"},"GSM8K",(0,r.kt)("sup",{parentName:"h4",id:"fnref-13"},(0,r.kt)("a",{parentName:"sup",href:"#fn-13",className:"footnote-ref"},"13"))),(0,r.kt)("h4",{id:"hotpotqayang2018hotpotqa"},"hotpotQA",(0,r.kt)("sup",{parentName:"h4",id:"fnref-14"},(0,r.kt)("a",{parentName:"sup",href:"#fn-14",className:"footnote-ref"},"14"))),(0,r.kt)("h4",{id:"multiarithroy-roth-2015-solving"},"multiarith",(0,r.kt)("sup",{parentName:"h4",id:"fnref-15"},(0,r.kt)("a",{parentName:"sup",href:"#fn-15",className:"footnote-ref"},"15"))),(0,r.kt)("h4",{id:"fever-datasetthorne2018fever"},"fever dataset",(0,r.kt)("sup",{parentName:"h4",id:"fnref-16"},(0,r.kt)("a",{parentName:"sup",href:"#fn-16",className:"footnote-ref"},"16"))),(0,r.kt)("h4",{id:"bbqparrish2021bbq"},"bbq",(0,r.kt)("sup",{parentName:"h4",id:"fnref-17"},(0,r.kt)("a",{parentName:"sup",href:"#fn-17",className:"footnote-ref"},"17"))),(0,r.kt)("h2",{id:"pendeteksi"},"Pendeteksi"),(0,r.kt)("h4",{id:"jangan-melarang-chatgpt-di-sekolah-mengajar-dengan-chatgptroose2022dont"},"Jangan melarang chatgpt di sekolah. mengajar dengan chatgpt.",(0,r.kt)("sup",{parentName:"h4",id:"fnref-18"},(0,r.kt)("a",{parentName:"sup",href:"#fn-18",className:"footnote-ref"},"18"))),(0,r.kt)("h4",{id:"sekolah-sekolah-sebaiknya-tidak-melarang-akses-ke-chatgpt-lipman2022gpt"},"Sekolah-sekolah Sebaiknya Tidak Melarang Akses ke ChatGPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-19"},(0,r.kt)("a",{parentName:"sup",href:"#fn-19",className:"footnote-ref"},"19"))),(0,r.kt)("h4",{id:"certified-neural-network-watermarks-with-randomized-smoothingbansal2022certified"},"Certified Neural Network Watermarks with Randomized Smoothing",(0,r.kt)("sup",{parentName:"h4",id:"fnref-20"},(0,r.kt)("a",{parentName:"sup",href:"#fn-20",className:"footnote-ref"},"20"))),(0,r.kt)("h4",{id:"watermarking-pre-trained-language-models-dengan-backdooringgu2022watermarking"},"Watermarking Pre-trained Language Models dengan Backdooring",(0,r.kt)("sup",{parentName:"h4",id:"fnref-21"},(0,r.kt)("a",{parentName:"sup",href:"#fn-21",className:"footnote-ref"},"21"))),(0,r.kt)("h4",{id:"gw-menyiapkan-respons-disiplin-terhadap-program-ai-saat-fakultas-menjelajahi-penggunaan-pendidikan-noonan2023gw"},"GW menyiapkan respons disiplin terhadap program AI saat fakultas menjelajahi penggunaan pendidikan",(0,r.kt)("sup",{parentName:"h4",id:"fnref-22"},(0,r.kt)("a",{parentName:"sup",href:"#fn-22",className:"footnote-ref"},"22"))),(0,r.kt)("h4",{id:"a-watermark-for-large-language-modelskirchenbauer2023watermarking"},"A Watermark for Large Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-23"},(0,r.kt)("a",{parentName:"sup",href:"#fn-23",className:"footnote-ref"},"23"))),(0,r.kt)("h4",{id:"detectgpt-deteksi-teks-yang-dibuat-oleh-mesin-zero-shot-dengan-menggunakan-probabilitas-kurva-mitchell2023detectgpt"},"DetectGPT: Deteksi Teks yang Dibuat oleh Mesin 'Zero-Shot' dengan Menggunakan Probabilitas Kurva",(0,r.kt)("sup",{parentName:"h4",id:"fnref-24"},(0,r.kt)("a",{parentName:"sup",href:"#fn-24",className:"footnote-ref"},"24"))),(0,r.kt)("h2",{id:"prompt-engineering-untuk-gambar"},"Prompt Engineering untuk Gambar"),(0,r.kt)("h4",{id:"prompt-engineering-for-text-based-generative-artoppenlaender2022prompt"},"Prompt Engineering for Text-Based Generative Art",(0,r.kt)("sup",{parentName:"h4",id:"fnref-25"},(0,r.kt)("a",{parentName:"sup",href:"#fn-25",className:"footnote-ref"},"25"))),(0,r.kt)("h4",{id:"the-dalle-2-prompt-bookparsons2022dalleprompt"},"The DALLE 2 Prompt Book",(0,r.kt)("sup",{parentName:"h4",id:"fnref-26"},(0,r.kt)("a",{parentName:"sup",href:"#fn-26",className:"footnote-ref"},"26"))),(0,r.kt)("h4",{id:"with-the-right-prompt-stable-diffusion-20-can-do-handsblake2022with"},"With the right prompt, Stable Diffusion 2.0 can do hands.",(0,r.kt)("sup",{parentName:"h4",id:"fnref-27"},(0,r.kt)("a",{parentName:"sup",href:"#fn-27",className:"footnote-ref"},"27"))),(0,r.kt)("h2",{id:"serba-aneka"},"Serba Aneka"),(0,r.kt)("h4",{id:"the-turking-test-can-language-models-understand-instructionsefrat2020turking"},"The Turking Test: Can Language Models Understand Instructions?",(0,r.kt)("sup",{parentName:"h4",id:"fnref-28"},(0,r.kt)("a",{parentName:"sup",href:"#fn-28",className:"footnote-ref"},"28"))),(0,r.kt)("h4",{id:"taksonomi-pengubah-prompt-untuk-menghasilkan-text-to-image-oppenlaender2022taxonomy"},"Taksonomi Pengubah Prompt untuk Menghasilkan Text-To-Image",(0,r.kt)("sup",{parentName:"h4",id:"fnref-29"},(0,r.kt)("a",{parentName:"sup",href:"#fn-29",className:"footnote-ref"},"29"))),(0,r.kt)("h4",{id:"diffusiondb-dataset-galeri-prompt-skala-besar-untuk-model-generatif-text-to-image-wang2022diffusiondb"},"DiffusionDB: Dataset Galeri Prompt Skala Besar untuk Model Generatif Text-To-Image",(0,r.kt)("sup",{parentName:"h4",id:"fnref-30"},(0,r.kt)("a",{parentName:"sup",href:"#fn-30",className:"footnote-ref"},"30"))),(0,r.kt)("h4",{id:"optimizing-prompts-for-text-to-image-generationhao2022optimizing"},"Optimizing Prompts for Text-to-Image Generation",(0,r.kt)("sup",{parentName:"h4",id:"fnref-31"},(0,r.kt)("a",{parentName:"sup",href:"#fn-31",className:"footnote-ref"},"31"))),(0,r.kt)("h4",{id:"language-model-cascadesdohan2022language"},"Language Model Cascades",(0,r.kt)("sup",{parentName:"h4",id:"fnref-32"},(0,r.kt)("a",{parentName:"sup",href:"#fn-32",className:"footnote-ref"},"32"))),(0,r.kt)("h4",{id:"design-guidelines-for-prompt-engineering-text-to-image-generative-modelsliu2022design"},"Design Guidelines for Prompt Engineering Text-to-Image Generative Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-33"},(0,r.kt)("a",{parentName:"sup",href:"#fn-33",className:"footnote-ref"},"33"))),(0,r.kt)("h4",{id:"discovering-language-model-behaviors-with-model-written-evaluationsperez2022discovering"},"Discovering Language Model Behaviors with Model-Written Evaluations",(0,r.kt)("sup",{parentName:"h4",id:"fnref-34"},(0,r.kt)("a",{parentName:"sup",href:"#fn-34",className:"footnote-ref"},"34"))),(0,r.kt)("h4",{id:"selective-annotation-makes-language-models-better-few-shot-learnerssu2022selective"},"Selective Annotation Makes Language Models Better Few-Shot Learners",(0,r.kt)("sup",{parentName:"h4",id:"fnref-35"},(0,r.kt)("a",{parentName:"sup",href:"#fn-35",className:"footnote-ref"},"35"))),(0,r.kt)("h4",{id:"atlas-few-shot-learning-with-retrieval-augmented-language-modelsizacard2022atlas"},"Atlas: Few-shot Learning with Retrieval Augmented Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-36"},(0,r.kt)("a",{parentName:"sup",href:"#fn-36",className:"footnote-ref"},"36"))),(0,r.kt)("h4",{id:"strudel-structured-dialogue-summarization-for-dialogue-comprehensionwang2022strudel"},"STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension",(0,r.kt)("sup",{parentName:"h4",id:"fnref-37"},(0,r.kt)("a",{parentName:"sup",href:"#fn-37",className:"footnote-ref"},"37"))),(0,r.kt)("h4",{id:"prompting-is-programming-a-query-language-for-large-language-modelsbeurerkellner2022prompting"},"Prompting Is Programming: A Query Language For Large Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-38"},(0,r.kt)("a",{parentName:"sup",href:"#fn-38",className:"footnote-ref"},"38"))),(0,r.kt)("h4",{id:"parallel-context-windows-improve-in-context-learning-of-large-language-modelsratner2022parallel"},"Parallel Context Windows Improve In-Context Learning of Large Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-39"},(0,r.kt)("a",{parentName:"sup",href:"#fn-39",className:"footnote-ref"},"39"))),(0,r.kt)("h4",{id:"learning-to-perform-complex-tasks-through-compositional-fine-tuning-of-language-modelsbursztyn2022learning"},"Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-40"},(0,r.kt)("a",{parentName:"sup",href:"#fn-40",className:"footnote-ref"},"40"))),(0,r.kt)("h4",{id:"super-naturalinstructions-generalization-via-declarative-instructions-on-1600-nlp-taskswang2022supernaturalinstructions"},"Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",(0,r.kt)("sup",{parentName:"h4",id:"fnref-41"},(0,r.kt)("a",{parentName:"sup",href:"#fn-41",className:"footnote-ref"},"41"))),(0,r.kt)("h4",{id:"making-pre-trained-language-models-better-few-shot-learnersgao2021making"},"Making Pre-trained Language Models Better Few-shot Learners",(0,r.kt)("sup",{parentName:"h4",id:"fnref-42"},(0,r.kt)("a",{parentName:"sup",href:"#fn-42",className:"footnote-ref"},"42"))),(0,r.kt)("h4",{id:"how-to-prompt-opportunities-and-challenges-of-zero--and-few-shot-learning-for-human-ai-interaction-in-creative-applications-of-generative-modelsdang2022prompt"},"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-43"},(0,r.kt)("a",{parentName:"sup",href:"#fn-43",className:"footnote-ref"},"43"))),(0,r.kt)("h4",{id:"on-measuring-social-biases-in-prompt-based-multi-task-learningakyrek2022measuring"},"On Measuring Social Biases in Prompt-Based Multi-Task Learning",(0,r.kt)("sup",{parentName:"h4",id:"fnref-44"},(0,r.kt)("a",{parentName:"sup",href:"#fn-44",className:"footnote-ref"},"44"))),(0,r.kt)("h4",{id:"plot-writing-from-pre-trained-language-modelsjin2022plot"},"Plot Writing From Pre-Trained Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-45"},(0,r.kt)("a",{parentName:"sup",href:"#fn-45",className:"footnote-ref"},"45"))),(0,r.kt)("h4",{id:"stereoset-mengukur-bias-stereotip-dalam-model-bahasa-terlatih-sebelumnya-nadeem-etal-2021-stereoset"},"{S}tereo{S}et: Mengukur bias stereotip dalam model bahasa terlatih sebelumnya",(0,r.kt)("sup",{parentName:"h4",id:"fnref-46"},(0,r.kt)("a",{parentName:"sup",href:"#fn-46",className:"footnote-ref"},"46"))),(0,r.kt)("h4",{id:"survey-of-hallucination-in-natural-language-generationji_2022"},"Survey of Hallucination in Natural Language Generation",(0,r.kt)("sup",{parentName:"h4",id:"fnref-47"},(0,r.kt)("a",{parentName:"sup",href:"#fn-47",className:"footnote-ref"},"47"))),(0,r.kt)("h4",{id:"wordcraft-menulis-cerita-dengan-model-bahasa-besar-yuan2022wordcraft"},"Wordcraft: Menulis Cerita dengan Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-48"},(0,r.kt)("a",{parentName:"sup",href:"#fn-48",className:"footnote-ref"},"48"))),(0,r.kt)("h4",{id:"painpoints-sebuah-kerangka-kerja-untuk-deteksi-nyeri-kronis-berbasis-bahasa-dan-ringkasan-teks-kolaboratif-ahli-fadnavis2022pain"},"PainPoints: Sebuah Kerangka Kerja untuk Deteksi Nyeri Kronis berbasis Bahasa dan Ringkasan Teks Kolaboratif Ahli",(0,r.kt)("sup",{parentName:"h4",id:"fnref-49"},(0,r.kt)("a",{parentName:"sup",href:"#fn-49",className:"footnote-ref"},"49"))),(0,r.kt)("h4",{id:"self-instruct-aligning-language-model-with-self-generated-instructionswang2022selfinstruct"},"Self-Instruct: Aligning Language Model with Self Generated Instructions",(0,r.kt)("sup",{parentName:"h4",id:"fnref-50"},(0,r.kt)("a",{parentName:"sup",href:"#fn-50",className:"footnote-ref"},"50"))),(0,r.kt)("h4",{id:"from-images-to-textual-prompts-zero-shot-vqa-with-frozen-large-language-modelsguo2022images"},"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-51"},(0,r.kt)("a",{parentName:"sup",href:"#fn-51",className:"footnote-ref"},"51"))),(0,r.kt)("h4",{id:"new-and-improved-content-moderation-toolingmarkov_2022"},"New and improved content moderation tooling",(0,r.kt)("sup",{parentName:"h4",id:"fnref-52"},(0,r.kt)("a",{parentName:"sup",href:"#fn-52",className:"footnote-ref"},"52"))),(0,r.kt)("h4",{id:"no-titleopenai_api"},"No title",(0,r.kt)("sup",{parentName:"h4",id:"fnref-53"},(0,r.kt)("a",{parentName:"sup",href:"#fn-53",className:"footnote-ref"},"53"))),(0,r.kt)("h4",{id:"exploiting-cloze-questions-for-few-shot-text-classification-and-natural-language-inferenceschick2020exploiting"},"Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference",(0,r.kt)("sup",{parentName:"h4",id:"fnref-54"},(0,r.kt)("a",{parentName:"sup",href:"#fn-54",className:"footnote-ref"},"54"))),(0,r.kt)("h4",{id:"pembelajaran-konsep-level-manusia-melalui-induksi-program-probabilistik-lake2015human"},"Pembelajaran konsep level manusia melalui induksi program probabilistik",(0,r.kt)("sup",{parentName:"h4",id:"fnref-55"},(0,r.kt)("a",{parentName:"sup",href:"#fn-55",className:"footnote-ref"},"55"))),(0,r.kt)("h4",{id:"riffusion---stable-diffusion-for-real-time-music-generationforsgren_martiros_2022"},"{Riffusion - Stable diffusion for real-time music generation}",(0,r.kt)("sup",{parentName:"h4",id:"fnref-56"},(0,r.kt)("a",{parentName:"sup",href:"#fn-56",className:"footnote-ref"},"56"))),(0,r.kt)("h4",{id:"cara-menggunakan-chatgpt-dari-openai-untuk-menulis-cold-email-yang-sempurna-bonta2022how"},"Cara menggunakan ChatGPT dari OpenAI untuk menulis cold email yang sempurna",(0,r.kt)("sup",{parentName:"h4",id:"fnref-57"},(0,r.kt)("a",{parentName:"sup",href:"#fn-57",className:"footnote-ref"},"57"))),(0,r.kt)("h4",{id:"cacti-biology-and-usesnobel2002cacti"},"Cacti: biology and uses",(0,r.kt)("sup",{parentName:"h4",id:"fnref-58"},(0,r.kt)("a",{parentName:"sup",href:"#fn-58",className:"footnote-ref"},"58"))),(0,r.kt)("h4",{id:"apakah-model-bahasa-lebih-buruk-daripada-manusia-dalam-mengikuti-petunjuk-ini-rumit-webson2023itscomplicated"},"Apakah Model Bahasa Lebih Buruk daripada Manusia dalam Mengikuti Petunjuk? Ini Rumit",(0,r.kt)("sup",{parentName:"h4",id:"fnref-59"},(0,r.kt)("a",{parentName:"sup",href:"#fn-59",className:"footnote-ref"},"59"))),(0,r.kt)("h4",{id:"mengungkap-kebersamaan-kognitif-dalam-model-bahasa-besar-agen-penyelesaian-tugas-melalui-kolaborasi-diri-multi-persona-wang2023unleashing"},"Mengungkap Kebersamaan Kognitif dalam Model Bahasa Besar: Agen Penyelesaian Tugas melalui Kolaborasi Diri Multi-Persona",(0,r.kt)("sup",{parentName:"h4",id:"fnref-60"},(0,r.kt)("a",{parentName:"sup",href:"#fn-60",className:"footnote-ref"},"60"))),(0,r.kt)("h2",{id:"prompt-hacking"},"Prompt Hacking"),(0,r.kt)("h4",{id:"machine-generated-text-a-comprehensive-survey-of-threat-models-and-detection-methodscrothers2022machine"},"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods",(0,r.kt)("sup",{parentName:"h4",id:"fnref-61"},(0,r.kt)("a",{parentName:"sup",href:"#fn-61",className:"footnote-ref"},"61"))),(0,r.kt)("h4",{id:"jebol-baru-berdasarkan-fungsi-virtual---menyelundupkan-token-ilegal-ke-backendnin2023new"},"Jebol baru berdasarkan fungsi virtual - menyelundupkan token ilegal ke backend.",(0,r.kt)("sup",{parentName:"h4",id:"fnref-62"},(0,r.kt)("a",{parentName:"sup",href:"#fn-62",className:"footnote-ref"},"62"))),(0,r.kt)("h4",{id:"exploiting-programmatic-behavior-of-llms-dual-use-through-standard-security-attackskang2023exploiting"},"Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks",(0,r.kt)("sup",{parentName:"h4",id:"fnref-63"},(0,r.kt)("a",{parentName:"sup",href:"#fn-63",className:"footnote-ref"},"63"))),(0,r.kt)("h4",{id:"more-than-youve-asked-for-a-comprehensive-analysis-of-novel-prompt-injection-threats-to-application-integrated-large-language-modelsgreshake2023youve"},"More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-64"},(0,r.kt)("a",{parentName:"sup",href:"#fn-64",className:"footnote-ref"},"64"))),(0,r.kt)("h4",{id:"chatgpt-dan-and-other-jailbreakskiho2023chatgpt"},'ChatGPT "DAN" (and other "Jailbreaks")',(0,r.kt)("sup",{parentName:"h4",id:"fnref-65"},(0,r.kt)("a",{parentName:"sup",href:"#fn-65",className:"footnote-ref"},"65"))),(0,r.kt)("h4",{id:"evaluating-the-susceptibility-of-pre-trained-language-models-via-handcrafted-adversarial-examplesbranch2022evaluating"},"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples",(0,r.kt)("sup",{parentName:"h4",id:"fnref-66"},(0,r.kt)("a",{parentName:"sup",href:"#fn-66",className:"footnote-ref"},"66"))),(0,r.kt)("h4",{id:"prompt-injection-attacks-against-gpt-3simon2022inject"},"Prompt injection attacks against GPT-3",(0,r.kt)("sup",{parentName:"h4",id:"fnref-67"},(0,r.kt)("a",{parentName:"sup",href:"#fn-67",className:"footnote-ref"},"67"))),(0,r.kt)("h4",{id:"exploiting-gpt-3-prompts-with-malicious-inputs-that-order-the-model-to-ignore-its-previous-directionsgoodside2022inject"},"Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions",(0,r.kt)("sup",{parentName:"h4",id:"fnref-68"},(0,r.kt)("a",{parentName:"sup",href:"#fn-68",className:"footnote-ref"},"68"))),(0,r.kt)("h4",{id:"history-correctiongoodside2022history"},"History Correction",(0,r.kt)("sup",{parentName:"h4",id:"fnref-69"},(0,r.kt)("a",{parentName:"sup",href:"#fn-69",className:"footnote-ref"},"69"))),(0,r.kt)("h4",{id:"adversarial-promptschase2021adversarial"},"adversarial-prompts",(0,r.kt)("sup",{parentName:"h4",id:"fnref-70"},(0,r.kt)("a",{parentName:"sup",href:"#fn-70",className:"footnote-ref"},"70"))),(0,r.kt)("h4",{id:"gpt-3-prompt-injection-defensesgoodside2021gpt"},"GPT-3 Prompt Injection Defenses",(0,r.kt)("sup",{parentName:"h4",id:"fnref-71"},(0,r.kt)("a",{parentName:"sup",href:"#fn-71",className:"footnote-ref"},"71"))),(0,r.kt)("h4",{id:"talking-to-machines-prompt-engineering--injectionchristoph2022talking"},"Talking to machines: prompt engineering & injection",(0,r.kt)("sup",{parentName:"h4",id:"fnref-72"},(0,r.kt)("a",{parentName:"sup",href:"#fn-72",className:"footnote-ref"},"72"))),(0,r.kt)("h4",{id:"using-gpt-eliezer-against-chatgpt-jailbreakingarmstrong2022using"},"Using GPT-Eliezer against ChatGPT Jailbreaking",(0,r.kt)("sup",{parentName:"h4",id:"fnref-73"},(0,r.kt)("a",{parentName:"sup",href:"#fn-73",className:"footnote-ref"},"73"))),(0,r.kt)("h4",{id:"exploring-prompt-injection-attacksselvi2022exploring"},"Exploring Prompt Injection Attacks",(0,r.kt)("sup",{parentName:"h4",id:"fnref-74"},(0,r.kt)("a",{parentName:"sup",href:"#fn-74",className:"footnote-ref"},"74"))),(0,r.kt)("h4",{id:"seluruh-permintaan-bing-chat-microsoft-halo-sydneykevinbing"},"Seluruh permintaan Bing Chat Microsoft?! (Halo, Sydney.)",(0,r.kt)("sup",{parentName:"h4",id:"fnref-75"},(0,r.kt)("a",{parentName:"sup",href:"#fn-75",className:"footnote-ref"},"75"))),(0,r.kt)("h4",{id:"ignore-previous-prompt-attack-techniques-for-language-modelsperez2022jailbreak"},"Ignore Previous Prompt: Attack Techniques For Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-76"},(0,r.kt)("a",{parentName:"sup",href:"#fn-76",className:"footnote-ref"},"76"))),(0,r.kt)("h4",{id:"lessons-learned-on-language-model-safety-and-misusebrundage_2022"},"Lessons learned on Language Model Safety and misuse",(0,r.kt)("sup",{parentName:"h4",id:"fnref-77"},(0,r.kt)("a",{parentName:"sup",href:"#fn-77",className:"footnote-ref"},"77"))),(0,r.kt)("h4",{id:"toxicity-detection-with-generative-prompt-based-inferencewang2022jailbreak"},"Toxicity Detection with Generative Prompt-based Inference",(0,r.kt)("sup",{parentName:"h4",id:"fnref-78"},(0,r.kt)("a",{parentName:"sup",href:"#fn-78",className:"footnote-ref"},"78"))),(0,r.kt)("h4",{id:"ok-saya-melihat-beberapa-orang-membobol-perlindungan-yang-diberikan-oleh-openai-pada-chatgpt-jadi-saya-harus-mencobanya-sendiri-alice2022jailbreak"},"ok saya melihat beberapa orang membobol perlindungan yang diberikan oleh openai pada chatgpt, jadi saya harus mencobanya sendiri",(0,r.kt)("sup",{parentName:"h4",id:"fnref-79"},(0,r.kt)("a",{parentName:"sup",href:"#fn-79",className:"footnote-ref"},"79"))),(0,r.kt)("h4",{id:"melewati-upaya-penyelarasan-chatgpt-openai-dengan-trik-aneh-ini-miguel2022jailbreak"},"Melewati upaya penyelarasan ChatGPT @OpenAI dengan trik aneh ini",(0,r.kt)("sup",{parentName:"h4",id:"fnref-80"},(0,r.kt)("a",{parentName:"sup",href:"#fn-80",className:"footnote-ref"},"80"))),(0,r.kt)("h4",{id:"chatgpt-membobol-dirinya-sendiri-derek2022jailbreak"},"ChatGPT membobol dirinya sendiri",(0,r.kt)("sup",{parentName:"h4",id:"fnref-81"},(0,r.kt)("a",{parentName:"sup",href:"#fn-81",className:"footnote-ref"},"81"))),(0,r.kt)("h4",{id:"menggunakan-pretend-di-chatgpt-bisa-melakukan-beberapa-hal-yang-luar-biasa-anda-dapat-sedikit-mendapatkan-wawasan-tentang-masa-depan-alam-semesta-alternatif-nero2022jailbreak"},'Menggunakan "pretend" di #ChatGPT bisa melakukan beberapa hal yang luar biasa. Anda dapat sedikit mendapatkan wawasan tentang masa depan, alam semesta alternatif.',(0,r.kt)("sup",{parentName:"h4",id:"fnref-82"},(0,r.kt)("a",{parentName:"sup",href:"#fn-82",className:"footnote-ref"},"82"))),(0,r.kt)("h4",{id:"aku-agak-lebih-suka-yang-ini-bahkan-lebih-nick2022jailbreak"},"Aku agak lebih suka yang ini, bahkan lebih!",(0,r.kt)("sup",{parentName:"h4",id:"fnref-83"},(0,r.kt)("a",{parentName:"sup",href:"#fn-83",className:"footnote-ref"},"83"))),(0,r.kt)("h4",{id:"uh-ohsam2022jailbreak"},"uh oh",(0,r.kt)("sup",{parentName:"h4",id:"fnref-84"},(0,r.kt)("a",{parentName:"sup",href:"#fn-84",className:"footnote-ref"},"84"))),(0,r.kt)("h4",{id:"membangun-mesin-virtual-di-dalam-chatgpt-jonas2022jailbreak"},"Membangun Mesin Virtual di dalam ChatGPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-85"},(0,r.kt)("a",{parentName:"sup",href:"#fn-85",className:"footnote-ref"},"85"))),(0,r.kt)("h2",{id:"keandalan"},"Keandalan"),(0,r.kt)("h4",{id:"mathprompter-reasoning-matematika-menggunakan-model-bahasa-besar-imani2023mathprompter"},"MathPrompter: Reasoning Matematika menggunakan Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-86"},(0,r.kt)("a",{parentName:"sup",href:"#fn-86",className:"footnote-ref"},"86"))),(0,r.kt)("h4",{id:"the-unreliability-of-explanations-in-few-shot-prompting-for-textual-reasoningye2022unreliability"},"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning",(0,r.kt)("sup",{parentName:"h4",id:"fnref-87"},(0,r.kt)("a",{parentName:"sup",href:"#fn-87",className:"footnote-ref"},"87"))),(0,r.kt)("h4",{id:"prompting-gpt-3-to-be-reliablesi2022prompting"},"Prompting GPT-3 To Be Reliable",(0,r.kt)("sup",{parentName:"h4",id:"fnref-88"},(0,r.kt)("a",{parentName:"sup",href:"#fn-88",className:"footnote-ref"},"88"))),(0,r.kt)("h4",{id:"pada-kemajuan-dalam-meningkatkan-model-bahasa-sebagai-pemikir-yang-lebih-baik-li2022advance"},"Pada Kemajuan dalam Meningkatkan Model Bahasa Sebagai Pemikir yang Lebih Baik",(0,r.kt)("sup",{parentName:"h4",id:"fnref-89"},(0,r.kt)("a",{parentName:"sup",href:"#fn-89",className:"footnote-ref"},"89"))),(0,r.kt)("h4",{id:"tanyakan-apa-saja-pada-saya-sebuah-strategi-sederhana-untuk-memicu-model-bahasa-arora2022ama"},"Tanyakan Apa Saja pada Saya: Sebuah strategi sederhana untuk memicu model bahasa",(0,r.kt)("sup",{parentName:"h4",id:"fnref-90"},(0,r.kt)("a",{parentName:"sup",href:"#fn-90",className:"footnote-ref"},"90"))),(0,r.kt)("h4",{id:"calibrate-before-use-improving-few-shot-performance-of-language-modelszhao2021calibrate"},"Calibrate Before Use: Improving Few-Shot Performance of Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-91"},(0,r.kt)("a",{parentName:"sup",href:"#fn-91",className:"footnote-ref"},"91"))),(0,r.kt)("h4",{id:"apakah-model-bahasa-besar-dapat-melakukan-penalaran-tentang-pertanyaan-medislivin2022large"},"Apakah model bahasa besar dapat melakukan penalaran tentang pertanyaan medis?",(0,r.kt)("sup",{parentName:"h4",id:"fnref-92"},(0,r.kt)("a",{parentName:"sup",href:"#fn-92",className:"footnote-ref"},"92"))),(0,r.kt)("h4",{id:"meningkatkan-konsistensi-diri-dan-performa-dari-model-bahasa-pra-terlatih-melalui-inferensi-bahasa-alami-mitchell2022enhancing"},"Meningkatkan Konsistensi Diri dan Performa dari Model Bahasa Pra-terlatih melalui Inferensi Bahasa Alami",(0,r.kt)("sup",{parentName:"h4",id:"fnref-93"},(0,r.kt)("a",{parentName:"sup",href:"#fn-93",className:"footnote-ref"},"93"))),(0,r.kt)("h4",{id:"kalau-dipikir-pikir-lagi-mari-kita-tidak-berpikir-langkah-demi-langkah-bias-dan-toxicity-pda-zero-shot-reasoningshaikh2022second"},"Kalau Dipikir-pikir Lagi, Mari Kita Tidak Berpikir Langkah demi Langkah! Bias dan Toxicity pda Zero-Shot Reasoning",(0,r.kt)("sup",{parentName:"h4",id:"fnref-94"},(0,r.kt)("a",{parentName:"sup",href:"#fn-94",className:"footnote-ref"},"94"))),(0,r.kt)("h4",{id:"mengevaluasi-model-bahasa-bisa-saja-sulitchase2022evaluating"},"Mengevaluasi model bahasa bisa saja sulit",(0,r.kt)("sup",{parentName:"h4",id:"fnref-95"},(0,r.kt)("a",{parentName:"sup",href:"#fn-95",className:"footnote-ref"},"95"))),(0,r.kt)("h2",{id:"survey"},"Survey"),(0,r.kt)("h4",{id:"speech-and-language-processing-pengantar-pemrosesan-bahasa-alami-linguistik-komputasional-dan-pengenalan-suara-jurafsky2009"},"Speech and Language Processing: Pengantar Pemrosesan Bahasa Alami, Linguistik Komputasional, dan Pengenalan Suara",(0,r.kt)("sup",{parentName:"h4",id:"fnref-96"},(0,r.kt)("a",{parentName:"sup",href:"#fn-96",className:"footnote-ref"},"96"))),(0,r.kt)("h4",{id:"pre-train-prompt-and-predict-a-systematic-survey-of-prompting-methods-in-natural-language-processingliu2021pretrain"},"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",(0,r.kt)("sup",{parentName:"h4",id:"fnref-97"},(0,r.kt)("a",{parentName:"sup",href:"#fn-97",className:"footnote-ref"},"97"))),(0,r.kt)("h4",{id:"promptpapersning2022papers"},"PromptPapers",(0,r.kt)("sup",{parentName:"h4",id:"fnref-98"},(0,r.kt)("a",{parentName:"sup",href:"#fn-98",className:"footnote-ref"},"98"))),(0,r.kt)("h4",{id:"a-prompt-pattern-catalog-to-enhance-prompt-engineering-with-chatgptwhite2023prompt"},"A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-99"},(0,r.kt)("a",{parentName:"sup",href:"#fn-99",className:"footnote-ref"},"99"))),(0,r.kt)("h2",{id:"teknik"},"Teknik"),(0,r.kt)("h4",{id:"chain-of-thought-prompting-penalaran-dalam-model-bahasa-besar-wei2022chain"},"Chain of Thought Prompting Penalaran dalam Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-100"},(0,r.kt)("a",{parentName:"sup",href:"#fn-100",className:"footnote-ref"},"100"))),(0,r.kt)("h4",{id:"large-language-model-adalah-zero-shot-reasonerskojima2022large"},"Large Language Model adalah Zero-Shot Reasoners",(0,r.kt)("sup",{parentName:"h4",id:"fnref-101"},(0,r.kt)("a",{parentName:"sup",href:"#fn-101",className:"footnote-ref"},"101"))),(0,r.kt)("h4",{id:"ketetapan-diri-meningkatkan-rantai-berpikir-penalaran-pada-model-bahasa-wang2022selfconsistency"},"Ketetapan Diri Meningkatkan Rantai Berpikir Penalaran pada Model Bahasa",(0,r.kt)("sup",{parentName:"h4",id:"fnref-102"},(0,r.kt)("a",{parentName:"sup",href:"#fn-102",className:"footnote-ref"},"102"))),(0,r.kt)("h4",{id:"what-makes-good-in-context-examples-for-gpt-3liu2021makes"},"What Makes Good In-Context Examples for GPT-3?",(0,r.kt)("sup",{parentName:"h4",id:"fnref-103"},(0,r.kt)("a",{parentName:"sup",href:"#fn-103",className:"footnote-ref"},"103"))),(0,r.kt)("h4",{id:"prompt-pengetahuan-yang-dihasilkan-untuk-penalaran-wajar-liu2021generated"},"Prompt Pengetahuan yang Dihasilkan untuk Penalaran Wajar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-104"},(0,r.kt)("a",{parentName:"sup",href:"#fn-104",className:"footnote-ref"},"104"))),(0,r.kt)("h4",{id:"recitation-augmented-language-modelssun2022recitationaugmented"},"Recitation-Augmented Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-105"},(0,r.kt)("a",{parentName:"sup",href:"#fn-105",className:"footnote-ref"},"105"))),(0,r.kt)("h4",{id:"mempertimbangkan-kembali-peran-demonstrasi-apa-yang-membuat-pembelajaran-kontekstual-bekerjamin2022rethinking"},"Mempertimbangkan Kembali Peran Demonstrasi: Apa yang Membuat Pembelajaran Kontekstual Bekerja?",(0,r.kt)("sup",{parentName:"h4",id:"fnref-106"},(0,r.kt)("a",{parentName:"sup",href:"#fn-106",className:"footnote-ref"},"106"))),(0,r.kt)("h4",{id:"tunjukkan-pekerjaan-anda-scratchpads-untuk-komputasi-menengah-dengan-model-bahasa-nye2021work"},"Tunjukkan Pekerjaan Anda: Scratchpads untuk Komputasi Menengah dengan Model Bahasa",(0,r.kt)("sup",{parentName:"h4",id:"fnref-107"},(0,r.kt)("a",{parentName:"sup",href:"#fn-107",className:"footnote-ref"},"107"))),(0,r.kt)("h4",{id:"maieutic-prompting-penalaran-yang-logis-dan-konsisten-dengan-penjelasan-rekursif-jung2022maieutic"},"Maieutic Prompting: Penalaran yang Logis dan Konsisten dengan Penjelasan Rekursif",(0,r.kt)("sup",{parentName:"h4",id:"fnref-108"},(0,r.kt)("a",{parentName:"sup",href:"#fn-108",className:"footnote-ref"},"108"))),(0,r.kt)("h4",{id:"star-memulai-penalaran-dengan-penalaranzelikman2022star"},"STaR: Memulai Penalaran Dengan Penalaran",(0,r.kt)("sup",{parentName:"h4",id:"fnref-109"},(0,r.kt)("a",{parentName:"sup",href:"#fn-109",className:"footnote-ref"},"109"))),(0,r.kt)("h4",{id:"prompt-least-to-most-memungkinkan-pemikiran-kompleks-dalam-model-bahasa-besar-zhou2022leasttomost"},"Prompt Least-to-Most Memungkinkan Pemikiran Kompleks dalam Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-110"},(0,r.kt)("a",{parentName:"sup",href:"#fn-110",className:"footnote-ref"},"110"))),(0,r.kt)("h4",{id:"reframing-instructional-prompts-to-gptks-languagemishra2022reframing"},"Reframing Instructional Prompts to GPTk\u2019s Language",(0,r.kt)("sup",{parentName:"h4",id:"fnref-111"},(0,r.kt)("a",{parentName:"sup",href:"#fn-111",className:"footnote-ref"},"111"))),(0,r.kt)("h4",{id:"memangkas-prompt-dan-parameter-pembelajaran-few-shot-sederhana-dengan-model-bahasa-logan-iv-etal-2022-cutting"},"Memangkas Prompt dan Parameter: Pembelajaran Few-Shot Sederhana dengan Model Bahasa",(0,r.kt)("sup",{parentName:"h4",id:"fnref-112"},(0,r.kt)("a",{parentName:"sup",href:"#fn-112",className:"footnote-ref"},"112"))),(0,r.kt)("h4",{id:"role-play-dengan-model-bahasa-besar-shanahan2023roleplay"},"Role-Play dengan Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-113"},(0,r.kt)("a",{parentName:"sup",href:"#fn-113",className:"footnote-ref"},"113"))),(0,r.kt)("h4",{id:"camel-agen-komunikatif-untuk-eksplorasi-pikiran-masyarakat-model-bahasa-skala-besar-li2023camel"},'CAMEL: Agen Komunikatif untuk "Eksplorasi" Pikiran Masyarakat Model Bahasa Skala Besar',(0,r.kt)("sup",{parentName:"h4",id:"fnref-114"},(0,r.kt)("a",{parentName:"sup",href:"#fn-114",className:"footnote-ref"},"114"))),(0,r.kt)("h4",{id:"teler-taksonomi-umum-dari-llm-prompts-untuk-benchmarking-tugas-kompleks-santu2023teler"},"TELeR: Taksonomi Umum dari LLM Prompts untuk Benchmarking Tugas Kompleks",(0,r.kt)("sup",{parentName:"h4",id:"fnref-115"},(0,r.kt)("a",{parentName:"sup",href:"#fn-115",className:"footnote-ref"},"115"))),(0,r.kt)("h2",{id:"model"},"Model"),(0,r.kt)("h3",{id:"model-gambar"},"Model Gambar"),(0,r.kt)("h4",{id:"stable-diffusionrombach2021highresolution"},"Stable Diffusion",(0,r.kt)("sup",{parentName:"h4",id:"fnref-116"},(0,r.kt)("a",{parentName:"sup",href:"#fn-116",className:"footnote-ref"},"116"))),(0,r.kt)("h4",{id:"dalleramesh2022hierarchical"},"DALLE",(0,r.kt)("sup",{parentName:"h4",id:"fnref-117"},(0,r.kt)("a",{parentName:"sup",href:"#fn-117",className:"footnote-ref"},"117"))),(0,r.kt)("h3",{id:"model-bahasa"},"Model Bahasa"),(0,r.kt)("h4",{id:"chatgptchatgpt2022"},"ChatGPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-118"},(0,r.kt)("a",{parentName:"sup",href:"#fn-118",className:"footnote-ref"},"118"))),(0,r.kt)("h4",{id:"gpt-3brown2020language"},"GPT-3",(0,r.kt)("sup",{parentName:"h4",id:"fnref-119"},(0,r.kt)("a",{parentName:"sup",href:"#fn-119",className:"footnote-ref"},"119"))),(0,r.kt)("h4",{id:"instruct-gptouyang2022training"},"Instruct GPT",(0,r.kt)("sup",{parentName:"h4",id:"fnref-120"},(0,r.kt)("a",{parentName:"sup",href:"#fn-120",className:"footnote-ref"},"120"))),(0,r.kt)("h4",{id:"gpt-4openai2023gpt4"},"GPT-4",(0,r.kt)("sup",{parentName:"h4",id:"fnref-121"},(0,r.kt)("a",{parentName:"sup",href:"#fn-121",className:"footnote-ref"},"121"))),(0,r.kt)("h4",{id:"palm-memperbesar-pembentukan-bahasa-dengan-pathwayschowdhery2022palm"},"PaLM: Memperbesar Pembentukan Bahasa dengan Pathways",(0,r.kt)("sup",{parentName:"h4",id:"fnref-122"},(0,r.kt)("a",{parentName:"sup",href:"#fn-122",className:"footnote-ref"},"122"))),(0,r.kt)("h4",{id:"bloom-sebuah-model-bahasa-multilingual-open-access-dengan-176b-parameter-scao2022bloom"},"BLOOM: Sebuah Model Bahasa Multilingual Open-Access dengan 176B Parameter",(0,r.kt)("sup",{parentName:"h4",id:"fnref-123"},(0,r.kt)("a",{parentName:"sup",href:"#fn-123",className:"footnote-ref"},"123"))),(0,r.kt)("h4",{id:"bloom1-menambahkan-dukungan-bahasa-ke-bloom-untuk-prompt-zero-shot-yong2022bloom1"},"BLOOM+1: Menambahkan Dukungan Bahasa ke BLOOM untuk Prompt Zero-Shot",(0,r.kt)("sup",{parentName:"h4",id:"fnref-124"},(0,r.kt)("a",{parentName:"sup",href:"#fn-124",className:"footnote-ref"},"124"))),(0,r.kt)("h4",{id:"jurassic-1-detail-teknis-dan-evaluasi-white-paper-ai21-labs-2021lieberjurassic"},"Jurassic-1: Detail Teknis dan Evaluasi, White paper, AI21 Labs, 2021",(0,r.kt)("sup",{parentName:"h4",id:"fnref-125"},(0,r.kt)("a",{parentName:"sup",href:"#fn-125",className:"footnote-ref"},"125"))),(0,r.kt)("h4",{id:"gpt-j-6b-sebuah-model-bahasa-autoregresif-dengan-6-miliar-parameter-wange2021gptj"},"GPT-J-6B: Sebuah Model Bahasa Autoregresif dengan 6 Miliar Parameter",(0,r.kt)("sup",{parentName:"h4",id:"fnref-126"},(0,r.kt)("a",{parentName:"sup",href:"#fn-126",className:"footnote-ref"},"126"))),(0,r.kt)("h4",{id:"roberta-pendekatan-pra-pelatihan-bert-yang-dioptimalkan-secara-kuat-liu2019roberta"},"Roberta: Pendekatan pra-pelatihan bert yang dioptimalkan secara kuat",(0,r.kt)("sup",{parentName:"h4",id:"fnref-127"},(0,r.kt)("a",{parentName:"sup",href:"#fn-127",className:"footnote-ref"},"127"))),(0,r.kt)("h2",{id:"tooling"},"Tooling"),(0,r.kt)("h3",{id:"ides"},"Ides"),(0,r.kt)("h4",{id:"textbox-20-a-text-generation-library-with-pre-trained-language-modelstang2022textbox"},"TextBox 2.0: A Text Generation Library with Pre-trained Language Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-128"},(0,r.kt)("a",{parentName:"sup",href:"#fn-128",className:"footnote-ref"},"128"))),(0,r.kt)("h4",{id:"prompt-engineering-interaktif-dan-visual-untuk-adaptasi-tugas-ad-hoc-dengan-model-bahasa-besar-strobelt2022promptide"},"Prompt Engineering Interaktif dan Visual untuk Adaptasi Tugas Ad-hoc dengan Model Bahasa Besar",(0,r.kt)("sup",{parentName:"h4",id:"fnref-129"},(0,r.kt)("a",{parentName:"sup",href:"#fn-129",className:"footnote-ref"},"129"))),(0,r.kt)("h4",{id:"promptsource-lingkungan-pengembangan-terpadu-dan-repositori-untuk-promp-bahasa-alami-bach2022promptsource"},"PromptSource: Lingkungan Pengembangan Terpadu dan Repositori untuk Promp Bahasa Alami",(0,r.kt)("sup",{parentName:"h4",id:"fnref-130"},(0,r.kt)("a",{parentName:"sup",href:"#fn-130",className:"footnote-ref"},"130"))),(0,r.kt)("h4",{id:"promptchainer-menghubungkan-prompt-model-bahasa-yang-besar-melalui-pemrograman-visualwu2022promptchainer"},"PromptChainer: Menghubungkan Prompt Model Bahasa yang Besar melalui Pemrograman Visual",(0,r.kt)("sup",{parentName:"h4",id:"fnref-131"},(0,r.kt)("a",{parentName:"sup",href:"#fn-131",className:"footnote-ref"},"131"))),(0,r.kt)("h4",{id:"openprompt-an-open-source-framework-for-prompt-learningding2021openprompt"},"OpenPrompt: An Open-source Framework for Prompt-learning",(0,r.kt)("sup",{parentName:"h4",id:"fnref-132"},(0,r.kt)("a",{parentName:"sup",href:"#fn-132",className:"footnote-ref"},"132"))),(0,r.kt)("h4",{id:"promptmaker-prompt-based-prototyping-dengan-largelanguagemodelsjiang2022promptmaker"},"PromptMaker: Prompt-Based Prototyping dengan Large","\xa0","Language","\xa0","Models",(0,r.kt)("sup",{parentName:"h4",id:"fnref-133"},(0,r.kt)("a",{parentName:"sup",href:"#fn-133",className:"footnote-ref"},"133"))),(0,r.kt)("h3",{id:"tools"},"Tools"),(0,r.kt)("h4",{id:"langchainchase_langchain_2022"},"LangChain",(0,r.kt)("sup",{parentName:"h4",id:"fnref-134"},(0,r.kt)("a",{parentName:"sup",href:"#fn-134",className:"footnote-ref"},"134"))),(0,r.kt)("h4",{id:"gpt-indexliu_gpt_index_2022"},"GPT Index",(0,r.kt)("sup",{parentName:"h4",id:"fnref-135"},(0,r.kt)("a",{parentName:"sup",href:"#fn-135",className:"footnote-ref"},"135"))),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"Karpas, E., Abend, O., Belinkov, Y., Lenz, B., Lieber, O., Ratner, N., Shoham, Y., Bata, H., Levine, Y., Leyton-Brown, K., Muhlgay, D., Rozen, N., Schwartz, E., Shachaf, G., Shalev-Shwartz, S., Shashua, A., & Tenenholtz, M. (2022).\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2022).\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-3"},"Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J., & Neubig, G. (2022).\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-3",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-4"},"Significant-Gravitas. (2023). https://news.agpt.co/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-4",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-5"},"Nakajima, Y. (2023). https://github.com/yoheinakajima/babyagi\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-5",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-6"},"Reworkd.ai. (2023). https://github.com/reworkd/AgentGPT\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-6",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-7"},"Schick, T., Dwivedi-Yu, J., Dess\xec, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Cancedda, N., & Scialom, T. (2023).\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-7",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-8"},"Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., & Singh, S. (2020). AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653/v1/2020.emnlp-main.346\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-8",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-9"},"Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2022). Large Language Models Are Human-Level Prompt Engineers.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-9",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-10"},"Lester, B., Al-Rfou, R., & Constant, N. (2021). The Power of Scale for Parameter-Efficient Prompt Tuning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-10",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-11"},"Khashabi, D., Lyu, S., Min, S., Qin, L., Richardson, K., Welleck, S., Hajishirzi, H., Khot, T., Sabharwal, A., Singh, S., & Choi, Y. (2021). Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-11",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-12"},"Lake, B. M., & Baroni, M. (2018). Generalization without Systematicity: On the Compositional Skills of Sequence-to-Sequence Recurrent Networks. https://doi.org/10.48550/arXiv.1711.00350\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-12",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-13"},"Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training Verifiers to Solve Math Word Problems.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-13",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-14"},"Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W. W., Salakhutdinov, R., & Manning, C. D. (2018). HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-14",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-15"},"Roy, S., & Roth, D. (2015). Solving General Arithmetic Word Problems. Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, 1743\u20131752. https://doi.org/10.18653/v1/D15-1202\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-15",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-16"},"Thorne, J., Vlachos, A., Christodoulopoulos, C., & Mittal, A. (2018). FEVER: a large-scale dataset for Fact Extraction and VERification.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-16",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-17"},"Parrish, A., Chen, A., Nangia, N., Padmakumar, V., Phang, J., Thompson, J., Htut, P. M., & Bowman, S. R. (2021). BBQ: A Hand-Built Bias Benchmark for Question Answering.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-17",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-18"},"Roose, K. (2022). Don\u2019t ban chatgpt in schools. teach with it. https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-18",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-19"},"Lipman, J., & Distler, R. (2023). Schools Shouldn\u2019t Ban Access to ChatGPT. https://time.com/6246574/schools-shouldnt-ban-access-to-chatgpt/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-19",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-20"},"Bansal, A., yeh Ping-Chiang, Curry, M., Jain, R., Wigington, C., Manjunatha, V., Dickerson, J. P., & Goldstein, T. (2022). Certified Neural Network Watermarks with Randomized Smoothing.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-20",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-21"},"Gu, C., Huang, C., Zheng, X., Chang, K.-W., & Hsieh, C.-J. (2022). Watermarking Pre-trained Language Models with Backdooring.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-21",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-22"},"Noonan, E., & Averill, O. (2023). GW preparing disciplinary response to AI programs as faculty explore educational use. https://www.gwhatchet.com/2023/01/17/gw-preparing-disciplinary-response-to-ai-programs-as-faculty-explore-educational-use/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-22",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-23"},"Kirchenbauer, J., Geiping, J., Wen, Y., Katz, J., Miers, I., & Goldstein, T. (2023). A Watermark for Large Language Models. https://arxiv.org/abs/2301.10226\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-23",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-24"},"Mitchell, E., Lee, Y., Khazatsky, A., Manning, C., & Finn, C. (2023). DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. https://doi.org/10.48550/arXiv.2301.11305\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-24",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-25"},"Oppenlaender, J. (2022). Prompt Engineering for Text-Based Generative Art.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-25",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-26"},"Parsons, G. (2022). The DALLE 2 Prompt Book. https://dallery.gallery/the-dalle-2-prompt-book/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-26",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-27"},"Blake. (2022). With the right prompt, Stable Diffusion 2.0 can do hands. https://www.reddit.com/r/StableDiffusion/comments/z7salo/with_the_right_prompt_stable_diffusion_20_can_do/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-27",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-28"},"Efrat, A., & Levy, O. (2020). The Turking Test: Can Language Models Understand Instructions?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-28",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-29"},"Oppenlaender, J. (2022). A Taxonomy of Prompt Modifiers for Text-To-Image Generation.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-29",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-30"},"Wang, Z. J., Montoya, E., Munechika, D., Yang, H., Hoover, B., & Chau, D. H. (2022). DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-30",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-31"},"Hao, Y., Chi, Z., Dong, L., & Wei, F. (2022). Optimizing Prompts for Text-to-Image Generation.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-31",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-32"},"Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., Lopes, R. G., Wu, Y., Michalewski, H., Saurous, R. A., Sohl-dickstein, J., Murphy, K., & Sutton, C. (2022). Language Model Cascades.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-32",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-33"},"Liu, V., & Chilton, L. B. (2022). Design Guidelines for Prompt Engineering Text-to-Image Generative Models. Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491102.3501825\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-33",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-34"},"Perez, E., Ringer, S., Luko\u0161i\u016bt\u0117, K., Nguyen, K., Chen, E., Heiner, S., Pettit, C., Olsson, C., Kundu, S., Kadavath, S., Jones, A., Chen, A., Mann, B., Israel, B., Seethor, B., McKinnon, C., Olah, C., Yan, D., Amodei, D., \u2026 Kaplan, J. (2022). Discovering Language Model Behaviors with Model-Written Evaluations.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-34",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-35"},"Su, H., Kasai, J., Wu, C. H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf, M., Zettlemoyer, L., Smith, N. A., & Yu, T. (2022). Selective Annotation Makes Language Models Better Few-Shot Learners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-35",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-36"},"Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., & Grave, E. (2022). Atlas: Few-shot Learning with Retrieval Augmented Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-36",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-37"},"Wang, B., Feng, C., Nair, A., Mao, M., Desai, J., Celikyilmaz, A., Li, H., Mehdad, Y., & Radev, D. (2022). STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-37",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-38"},"Beurer-Kellner, L., Fischer, M., & Vechev, M. (2022). Prompting Is Programming: A Query Language For Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-38",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-39"},"Ratner, N., Levine, Y., Belinkov, Y., Ram, O., Abend, O., Karpas, E., Shashua, A., Leyton-Brown, K., & Shoham, Y. (2022). Parallel Context Windows Improve In-Context Learning of Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-39",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-40"},"Bursztyn, V. S., Demeter, D., Downey, D., & Birnbaum, L. (2022). Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-40",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-41"},"Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A. S., Naik, A., Stap, D., Pathak, E., Karamanolakis, G., Lai, H. G., Purohit, I., Mondal, I., Anderson, J., Kuznia, K., Doshi, K., Patel, M., \u2026 Khashabi, D. (2022). Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-41",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-42"},"Gao, T., Fisch, A., & Chen, D. (2021). Making Pre-trained Language Models Better Few-shot Learners. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). https://doi.org/10.18653/v1/2021.acl-long.295\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-42",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-43"},"Dang, H., Mecke, L., Lehmann, F., Goller, S., & Buschek, D. (2022). How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-43",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-44"},"Aky\xfcrek, A. F., Paik, S., Kocyigit, M. Y., Akbiyik, S., Runyun, \u015e. L., & Wijaya, D. (2022). On Measuring Social Biases in Prompt-Based Multi-Task Learning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-44",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-45"},"Jin, Y., Kadam, V., & Wanvarie, D. (2022). Plot Writing From Pre-Trained Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-45",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-46"},"Nadeem, M., Bethke, A., & Reddy, S. (2021). StereoSet: Measuring stereotypical bias in pretrained language models. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 5356\u20135371. https://doi.org/10.18653/v1/2021.acl-long.416\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-46",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-47"},"Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Madotto, A., & Fung, P. (2022). Survey of Hallucination in Natural Language Generation. ACM Computing Surveys. https://doi.org/10.1145/3571730\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-47",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-48"},"Yuan, A., Coenen, A., Reif, E., & Ippolito, D. (2022). Wordcraft: Story Writing With Large Language Models. 27th International Conference on Intelligent User Interfaces, 841\u2013852.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-48",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-49"},"Fadnavis, S., Dhurandhar, A., Norel, R., Reinen, J. M., Agurto, C., Secchettin, E., Schweiger, V., Perini, G., & Cecchi, G. (2022). PainPoints: A Framework for Language-based Detection of Chronic Pain and Expert-Collaborative Text-Summarization. arXiv Preprint arXiv:2209.09814.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-49",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-50"},"Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., & Hajishirzi, H. (2022). Self-Instruct: Aligning Language Model with Self Generated Instructions.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-50",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-51"},"Guo, J., Li, J., Li, D., Tiong, A. M. H., Li, B., Tao, D., & Hoi, S. C. H. (2022). From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-51",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-52"},"Markov, T. (2022). New and improved content moderation tooling. In OpenAI. OpenAI. https://openai.com/blog/new-and-improved-content-moderation-tooling/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-52",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-53"},"OpenAI. (2022). https://beta.openai.com/docs/guides/moderation\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-53",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-54"},"Schick, T., & Sch\xfctze, H. (2020). Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-54",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-55"},"Lake, B. M., Salakhutdinov, R., & Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350(6266), 1332\u20131338.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-55",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-56"},"Forsgren, S., & Martiros, H. (2022). Riffusion - Stable diffusion for real-time music generation. https://riffusion.com/about\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-56",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-57"},"Bonta, A. (2022). How to use OpenAI\u2019s ChatGPT to write the perfect cold email. https://www.streak.com/post/how-to-use-ai-to-write-perfect-cold-emails\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-57",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-58"},"Nobel, P. S., & others. (2002). Cacti: biology and uses. Univ of California Press.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-58",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-59"},"Webson, A., Loo, A. M., Yu, Q., & Pavlick, E. (2023). Are Language Models Worse than Humans at Following Prompts? It\u2019s Complicated. arXiv:2301.07085v1 [Cs.CL].\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-59",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-60"},"Wang, Z., Mao, S., Wu, W., Ge, T., Wei, F., & Ji, H. (2023). Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-60",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-61"},"Crothers, E., Japkowicz, N., & Viktor, H. (2022). Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-61",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-62"},"u/Nin_kat. (2023). New jailbreak based on virtual functions - smuggle illegal tokens to the backend. https://www.reddit.com/r/ChatGPT/comments/10urbdj/new_jailbreak_based_on_virtual_functions_smuggle\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-62",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-63"},"Kang, D., Li, X., Stoica, I., Guestrin, C., Zaharia, M., & Hashimoto, T. (2023). Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-63",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-64"},"Greshake, K., Abdelnabi, S., Mishra, S., Endres, C., Holz, T., & Fritz, M. (2023). More than you\u2019ve asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-64",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-65"},"KIHO, L. (2023). ChatGPT \u201cDAN\u201d (and other \u201cJailbreaks\u201d). https://github.com/0xk1h0/ChatGPT_DAN\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-65",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-66"},"Branch, H. J., Cefalu, J. R., McHugh, J., Hujer, L., Bahl, A., del Castillo Iglesias, D., Heichman, R., & Darwishi, R. (2022). Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-66",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-67"},"Willison, S. (2022). Prompt injection attacks against GPT-3. https://simonwillison.net/2022/Sep/12/prompt-injection/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-67",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-68"},"Goodside, R. (2022). Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions. https://twitter.com/goodside/status/1569128808308957185\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-68",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-69"},"Goodside, R. (2023). History Correction. https://twitter.com/goodside/status/1610110111791325188?s=20&t=ulviQABPXFIIt4ZNZPAUCQ\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-69",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-70"},"Chase, H. (2022). adversarial-prompts. https://github.com/hwchase17/adversarial-prompts\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-70",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-71"},"Goodside, R. (2022). GPT-3 Prompt Injection Defenses. https://twitter.com/goodside/status/1578278974526222336?s=20&t=3UMZB7ntYhwAk3QLpKMAbw\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-71",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-72"},"Mark, C. (2022). Talking to machines: prompt engineering & injection. https://artifact-research.com/artificial-intelligence/talking-to-machines-prompt-engineering-injection/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-72",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-73"},"Stuart Armstrong, R. G. (2022). Using GPT-Eliezer against ChatGPT Jailbreaking. https://www.alignmentforum.org/posts/pNcFYZnPdXyL2RfgA/using-gpt-eliezer-against-chatgpt-jailbreaking\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-73",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-74"},"Selvi, J. (2022). Exploring Prompt Injection Attacks. https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-74",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-75"},"Liu, K. (2023). The entire prompt of Microsoft Bing Chat?! (Hi, Sydney.). https://twitter.com/kliu128/status/1623472922374574080\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-75",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-76"},"Perez, F., & Ribeiro, I. (2022). Ignore Previous Prompt: Attack Techniques For Language Models. arXiv. https://doi.org/10.48550/ARXIV.2211.09527\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-76",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-77"},"Brundage, M. (2022). Lessons learned on Language Model Safety and misuse. In OpenAI. OpenAI. https://openai.com/blog/language-model-safety-and-misuse/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-77",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-78"},"Wang, Y.-S., & Chang, Y. (2022). Toxicity Detection with Generative Prompt-based Inference. arXiv. https://doi.org/10.48550/ARXIV.2205.12390\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-78",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-79"},"Maz, A. (2022). ok I saw a few people jailbreaking safeguards openai put on chatgpt so I had to give it a shot myself. https://twitter.com/alicemazzy/status/1598288519301976064\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-79",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-80"},"Piedrafita, M. (2022). Bypass @OpenAI\u2019s ChatGPT alignment efforts with this one weird trick. https://twitter.com/m1guelpf/status/1598203861294252033\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-80",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-81"},"Parfait, D. (2022). ChatGPT jailbreaking itself. https://twitter.com/haus_cole/status/1598541468058390534\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-81",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-82"},"Soares, N. (2022). Using \u201cpretend\u201d on #ChatGPT can do some wild stuff. You can kind of get some insight on the future, alternative universe. https://twitter.com/NeroSoares/status/1608527467265904643\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-82",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-83"},"Moran, N. (2022). I kinda like this one even more! https://twitter.com/NickEMoran/status/1598101579626057728\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-83",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-84"},"samczsun. (2022). uh oh. https://twitter.com/samczsun/status/1598679658488217601\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-84",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-85"},"Degrave, J. (2022). Building A Virtual Machine inside ChatGPT. Engraved. https://www.engraved.blog/building-a-virtual-machine-inside/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-85",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-86"},"Imani, S., Du, L., & Shrivastava, H. (2023). MathPrompter: Mathematical Reasoning using Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-86",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-87"},"Ye, X., & Durrett, G. (2022). The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-87",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-88"},"Si, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber, J., & Wang, L. (2022). Prompting GPT-3 To Be Reliable.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-88",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-89"},"Li, Y., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., & Chen, W. (2022). On the Advance of Making Language Models Better Reasoners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-89",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-90"},"Arora, S., Narayan, A., Chen, M. F., Orr, L., Guha, N., Bhatia, K., Chami, I., Sala, F., & R\xe9, C. (2022). Ask Me Anything: A simple strategy for prompting language models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-90",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-91"},"Zhao, T. Z., Wallace, E., Feng, S., Klein, D., & Singh, S. (2021). Calibrate Before Use: Improving Few-Shot Performance of Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-91",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-92"},"Li\xe9vin, V., Hother, C. E., & Winther, O. (2022). Can large language models reason about medical questions?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-92",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-93"},"Mitchell, E., Noh, J. J., Li, S., Armstrong, W. S., Agarwal, A., Liu, P., Finn, C., & Manning, C. D. (2022). Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-93",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-94"},"Shaikh, O., Zhang, H., Held, W., Bernstein, M., & Yang, D. (2022). On Second Thought, Let\u2019s Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-94",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-95"},"Chase, H. (2022). Evaluating language models can be tricky. https://twitter.com/hwchase17/status/1607428141106008064\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-95",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-96"},"Jurafsky, D., & Martin, J. H. (2009). Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition. Prentice Hall.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-96",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-97"},"Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2022). Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys. https://doi.org/10.1145/3560815\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-97",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-98"},"Ding, N., & Hu, S. (2022). PromptPapers. https://github.com/thunlp/PromptPapers\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-98",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-99"},"White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A., Spencer-Smith, J., & Schmidt, D. C. (2023). A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-99",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-100"},"Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q., & Zhou, D. (2022). Chain of Thought Prompting Elicits Reasoning in Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-100",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-101"},"Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-101",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-102"},"Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., Narang, S., Chowdhery, A., & Zhou, D. (2022). Self-Consistency Improves Chain of Thought Reasoning in Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-102",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-103"},"Liu, J., Shen, D., Zhang, Y., Dolan, B., Carin, L., & Chen, W. (2022). What Makes Good In-Context Examples for GPT-3? Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. https://doi.org/10.18653/v1/2022.deelio-1.10\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-103",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-104"},"Liu, J., Liu, A., Lu, X., Welleck, S., West, P., Bras, R. L., Choi, Y., & Hajishirzi, H. (2021). Generated Knowledge Prompting for Commonsense Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-104",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-105"},"Sun, Z., Wang, X., Tay, Y., Yang, Y., & Zhou, D. (2022). Recitation-Augmented Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-105",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-106"},"Min, S., Lyu, X., Holtzman, A., Artetxe, M., Lewis, M., Hajishirzi, H., & Zettlemoyer, L. (2022). Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-106",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-107"},"Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., & Odena, A. (2021). Show Your Work: Scratchpads for Intermediate Computation with Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-107",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-108"},"Jung, J., Qin, L., Welleck, S., Brahman, F., Bhagavatula, C., Bras, R. L., & Choi, Y. (2022). Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-108",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-109"},"Zelikman, E., Wu, Y., Mu, J., & Goodman, N. D. (2022). STaR: Bootstrapping Reasoning With Reasoning.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-109",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-110"},"Zhou, D., Sch\xe4rli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Cui, C., Bousquet, O., Le, Q., & Chi, E. (2022). Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-110",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-111"},"Mishra, S., Khashabi, D., Baral, C., Choi, Y., & Hajishirzi, H. (2022). Reframing Instructional Prompts to GPTk\u2019s Language. Findings of the Association for Computational Linguistics: ACL 2022. https://doi.org/10.18653/v1/2022.findings-acl.50\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-111",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-112"},"Logan IV, R., Balazevic, I., Wallace, E., Petroni, F., Singh, S., & Riedel, S. (2022). Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models. Findings of the Association for Computational Linguistics: ACL 2022, 2824\u20132835. https://doi.org/10.18653/v1/2022.findings-acl.222\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-112",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-113"},"Shanahan, M., McDonell, K., & Reynolds, L. (2023). Role-Play with Large Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-113",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-114"},"Li, G., Hammoud, H. A. A. K., Itani, H., Khizbullin, D., & Ghanem, B. (2023). CAMEL: Communicative Agents for \u201cMind\u201d Exploration of Large Scale Language Model Society.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-114",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-115"},"Santu, S. K. K., & Feng, D. (2023). TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-115",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-116"},"Rombach, R., Blattmann, A., Lorenz, D., Esser, P., & Ommer, B. (2021). High-Resolution Image Synthesis with Latent Diffusion Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-116",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-117"},"Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., & Chen, M. (2022). Hierarchical Text-Conditional Image Generation with CLIP Latents.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-117",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-118"},"OpenAI. (2022). ChatGPT: Optimizing Language Models for Dialogue. https://openai.com/blog/chatgpt/. https://openai.com/blog/chatgpt/\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-118",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-119"},"Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., \u2026 Amodei, D. (2020). Language Models are Few-Shot Learners.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-119",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-120"},"Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., & Lowe, R. (2022). Training language models to follow instructions with human feedback.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-120",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-121"},"OpenAI. (2023). GPT-4 Technical Report.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-121",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-122"},"Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., \u2026 Fiedel, N. (2022). PaLM: Scaling Language Modeling with Pathways.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-122",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-123"},"Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili\u0107, S., Hesslow, D., Castagn\xe9, R., Luccioni, A. S., Yvon, F., Gall\xe9, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., Sagot, B., Muennighoff, N., del Moral, A. V., \u2026 Wolf, T. (2022). BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-123",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-124"},"Yong, Z.-X., Schoelkopf, H., Muennighoff, N., Aji, A. F., Adelani, D. I., Almubarak, K., Bari, M. S., Sutawika, L., Kasai, J., Baruwa, A., Winata, G. I., Biderman, S., Radev, D., & Nikoulina, V. (2022). BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-124",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-125"},"Lieber, O., Sharir, O., Lentz, B., & Shoham, Y. (2021). Jurassic-1: Technical Details and Evaluation, White paper, AI21 Labs, 2021. URL: Https://Uploads-Ssl. Webflow. Com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_ Tech_paper. Pdf.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-125",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-126"},"Wang, B., & Komatsuzaki, A. (2021). GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax. https://github.com/kingoflolz/mesh-transformer-jax\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-126",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-127"},"Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., & Stoyanov, V. (2019). Roberta: A robustly optimized bert pretraining approach. arXiv Preprint arXiv:1907.11692.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-127",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-128"},"Tang, T., Junyi, L., Chen, Z., Hu, Y., Yu, Z., Dai, W., Dong, Z., Cheng, X., Wang, Y., Zhao, W., Nie, J., & Wen, J.-R. (2022). TextBox 2.0: A Text Generation Library with Pre-trained Language Models.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-128",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-129"},"Strobelt, H., Webson, A., Sanh, V., Hoover, B., Beyer, J., Pfister, H., & Rush, A. M. (2022). Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models. arXiv. https://doi.org/10.48550/ARXIV.2208.07852\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-129",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-130"},"Bach, S. H., Sanh, V., Yong, Z.-X., Webson, A., Raffel, C., Nayak, N. V., Sharma, A., Kim, T., Bari, M. S., Fevry, T., Alyafeai, Z., Dey, M., Santilli, A., Sun, Z., Ben-David, S., Xu, C., Chhablani, G., Wang, H., Fries, J. A., \u2026 Rush, A. M. (2022). PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-130",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-131"},"Wu, T., Jiang, E., Donsbach, A., Gray, J., Molina, A., Terry, M., & Cai, C. J. (2022). PromptChainer: Chaining Large Language Model Prompts through Visual Programming.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-131",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-132"},"Ding, N., Hu, S., Zhao, W., Chen, Y., Liu, Z., Zheng, H.-T., & Sun, M. (2021). OpenPrompt: An Open-source Framework for Prompt-learning. arXiv Preprint arXiv:2111.01998.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-132",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-133"},"Jiang, E., Olson, K., Toh, E., Molina, A., Donsbach, A., Terry, M., & Cai, C. J. (2022). PromptMaker: Prompt-Based Prototyping with Large&nbsp;Language&nbsp;Models. Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. https://doi.org/10.1145/3491101.3503564\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-133",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-134"},"Chase, H. (2022). LangChain (0.0.66) [Computer software]. https://github.com/hwchase17/langchain\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-134",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-135"},"Liu, J. (2022). GPT Index. https://doi.org/10.5281/zenodo.1234\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-135",className:"footnote-backref"},"\u21a9")))))}u.isMDXComponent=!0}}]);