"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[8499],{3905:(e,a,o)=>{o.d(a,{Zo:()=>m,kt:()=>g});var n=o(67294);function r(e,a,o){return a in e?Object.defineProperty(e,a,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[a]=o,e}function t(e,a){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),o.push.apply(o,n)}return o}function s(e){for(var a=1;a<arguments.length;a++){var o=null!=arguments[a]?arguments[a]:{};a%2?t(Object(o),!0).forEach((function(a){r(e,a,o[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):t(Object(o)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(o,a))}))}return e}function i(e,a){if(null==e)return{};var o,n,r=function(e,a){if(null==e)return{};var o,n,r={},t=Object.keys(e);for(n=0;n<t.length;n++)o=t[n],a.indexOf(o)>=0||(r[o]=e[o]);return r}(e,a);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);for(n=0;n<t.length;n++)o=t[n],a.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(r[o]=e[o])}return r}var l=n.createContext({}),d=function(e){var a=n.useContext(l),o=a;return e&&(o="function"==typeof e?e(a):s(s({},a),e)),o},m=function(e){var a=d(e.components);return n.createElement(l.Provider,{value:a},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},p=n.forwardRef((function(e,a){var o=e.components,r=e.mdxType,t=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),u=d(o),p=r,g=u["".concat(l,".").concat(p)]||u[p]||c[p]||t;return o?n.createElement(g,s(s({ref:a},m),{},{components:o})):n.createElement(g,s({ref:a},m))}));function g(e,a){var o=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var t=o.length,s=new Array(t);s[0]=p;var i={};for(var l in a)hasOwnProperty.call(a,l)&&(i[l]=a[l]);i.originalType=e,i[u]="string"==typeof e?e:r,s[1]=i;for(var d=2;d<t;d++)s[d]=o[d];return n.createElement.apply(null,s)}return n.createElement.apply(null,o)}p.displayName="MDXCreateElement"},19921:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>l,contentTitle:()=>s,default:()=>c,frontMatter:()=>t,metadata:()=>i,toc:()=>d});var n=o(87462),r=(o(67294),o(3905));const t={sidebar_position:90},s="\ud83d\udcd9 Vocabul\xe1rio",i={unversionedId:"vocabulary",id:"vocabulary",title:"\ud83d\udcd9 Vocabul\xe1rio",description:"Consulte esta p\xe1gina para obter uma lista de termos e conceitos que usaremos ao longo deste curso.",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/vocabulary.md",sourceDirName:".",slug:"/vocabulary",permalink:"/pt/docs/vocabulary",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/vocabulary.md",tags:[],version:"current",sidebarPosition:90,frontMatter:{sidebar_position:90},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe2 Criando M\xfasica",permalink:"/pt/docs/miscl/music"},next:{title:"\ud83d\udcda Bibliography",permalink:"/pt/docs/bibliography"}},l={},d=[{value:"Modelos de Linguagem Grandes (LLMs), Modelos de Linguagem Pr\xe9-treinados (PLMs)(@branch2022evaluating), Modelos de Linguagem (LMs) e modelos fundamentais",id:"modelos-de-linguagem-grandes-llms-modelos-de-linguagem-pr\xe9-treinados-plmsbranch2022evaluating-modelos-de-linguagem-lms-e-modelos-fundamentais",level:4},{value:"Modelos de Linguagem Mascar\xe1veis (MLMs)",id:"modelos-de-linguagem-mascar\xe1veis-mlms",level:4},{value:"R\xf3tulos (labels, em ingl\xeas)",id:"r\xf3tulos-labels-em-ingl\xeas",level:4},{value:"Espa\xe7o de R\xf3tulos ou Categorias (Labelspace, em ingl\xeas)",id:"espa\xe7o-de-r\xf3tulos-ou-categorias-labelspace-em-ingl\xeas",level:4},{value:"Sentiment Analysis",id:"sentiment-analysis",level:4},{value:"&quot;Modelo&quot; vs. &quot;IA&quot; vs. &quot;LLM&quot;",id:"modelo-vs-ia-vs-llm",level:4},{value:"Aprendizado de M\xe1quina (ML, Machine Learning, em ingl\xeas)",id:"aprendizado-de-m\xe1quina-ml-machine-learning-em-ingl\xeas",level:4},{value:"Verbalizador",id:"verbalizador",level:4},{value:"Aprendizado por Refor\xe7o a partir de Feedback Humano (ARFH)",id:"aprendizado-por-refor\xe7o-a-partir-de-feedback-humano-arfh",level:4}],m={toc:d},u="wrapper";function c(e){let{components:a,...o}=e;return(0,r.kt)(u,(0,n.Z)({},m,o,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"-vocabul\xe1rio"},"\ud83d\udcd9 Vocabul\xe1rio"),(0,r.kt)("p",null,"Consulte esta p\xe1gina para obter uma lista de termos e conceitos que usaremos ao longo deste curso."),(0,r.kt)("h4",{id:"modelos-de-linguagem-grandes-llms-modelos-de-linguagem-pr\xe9-treinados-plmsbranch2022evaluating-modelos-de-linguagem-lms-e-modelos-fundamentais"},"Modelos de Linguagem Grandes (LLMs), Modelos de Linguagem Pr\xe9-treinados (PLMs)",(0,r.kt)("sup",{parentName:"h4",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1")),", Modelos de Linguagem (LMs) e modelos fundamentais"),(0,r.kt)("p",null,"Esses termos se referem mais ou menos \xe0 mesma coisa: AIs (redes neurais) grandes, que geralmente foram treinados em uma grande quantidade de texto."),(0,r.kt)("h4",{id:"modelos-de-linguagem-mascar\xe1veis-mlms"},"Modelos de Linguagem Mascar\xe1veis (MLMs)"),(0,r.kt)("p",null,"Os MLMs s\xe3o um tipo de modelo NLP, que t\xeam um token especial, geralmente ",(0,r.kt)("inlineCode",{parentName:"p"},"[MASK]"),', que \xe9 substitu\xeddo por uma palavra do vocabul\xe1rio. O modelo ent\xe3o prev\xea a palavra que foi mascarada. Por exemplo, se a frase \xe9 "O cachorro est\xe1 ',"[MASK]",' o gato", o modelo prev\xea "perseguindo" com alta probabilidade.'),(0,r.kt)("h4",{id:"r\xf3tulos-labels-em-ingl\xeas"},"R\xf3tulos (labels, em ingl\xeas)"),(0,r.kt)("p",null,"Digamos que queremos classificar alguns tweets como sendo ofensivos ou n\xe3o. Se tivermos uma lista de tweets e seu r\xf3tulo correspondente (ofensivo ou n\xe3o-ofensivo), podemos treinar um modelo para classificar se os tweets s\xe3o ofensivos ou n\xe3o. Os r\xf3tulos s\xe3o geralmente apenas possibilidades para a tarefa de classifica\xe7\xe3o."),(0,r.kt)("h4",{id:"espa\xe7o-de-r\xf3tulos-ou-categorias-labelspace-em-ingl\xeas"},"Espa\xe7o de R\xf3tulos ou Categorias (Labelspace, em ingl\xeas)"),(0,r.kt)("p",null,"Todos os poss\xedveis r\xf3tulos para uma determinada tarefa ('ofensivo' e 'n\xe3o-ofensivo' para o exemplo acima)."),(0,r.kt)("h4",{id:"sentiment-analysis"},"Sentiment Analysis"),(0,r.kt)("p",null,"Sentiment analysis is the task of classifying text into positive, negative, or other sentiments."),(0,r.kt)("h4",{id:"modelo-vs-ia-vs-llm"},'"Modelo" vs. "IA" vs. "LLM"'),(0,r.kt)("p",null,'Esses termos s\xe3o usados de forma intercambi\xe1vel ao longo deste curso, mas eles nem sempre significam a mesma coisa. LLMs s\xe3o um tipo de IA, como mencionado acima, mas nem todas as IAs s\xe3o LLMs. Quando mencionamos modelos neste curso, estamos nos referindo a modelos de IA. Portanto, neste curso, voc\xea pode considerar os termos "modelo" e "IA" como intercambi\xe1veis.'),(0,r.kt)("h4",{id:"aprendizado-de-m\xe1quina-ml-machine-learning-em-ingl\xeas"},"Aprendizado de M\xe1quina (ML, Machine Learning, em ingl\xeas)"),(0,r.kt)("p",null,"ML \xe9 um campo de estudo que se concentra em algoritmos que podem aprender com dados. ML \xe9 uma sub\xe1rea da IA."),(0,r.kt)("h4",{id:"verbalizador"},"Verbalizador"),(0,r.kt)("p",null,"No cen\xe1rio de classifica\xe7\xe3o, verbalizadores s\xe3o mapeamentos de r\xf3tulos para palavras no vocabul\xe1rio de um modelo de linguagem",(0,r.kt)("sup",{parentName:"p",id:"fnref-2"},(0,r.kt)("a",{parentName:"sup",href:"#fn-2",className:"footnote-ref"},"2")),". Por exemplo, considere realizar a classifica\xe7\xe3o de sentimento com o seguinte prompt:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-text"},"Tweet: \"I amo p\xe3o de queijo.\"\nQual o sentimento desse Tweet? Responda com 'pos' ou 'neg'.\n\n")),(0,r.kt)("p",null,"Nesse exemplo o verbalizador estar\xe1 mapeando os r\xf3tulos conceituais de ",(0,r.kt)("inlineCode",{parentName:"p"},"positivo")," e ",(0,r.kt)("inlineCode",{parentName:"p"},"negativo")," para os tokens ",(0,r.kt)("inlineCode",{parentName:"p"},"pos")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"neg"),"."),(0,r.kt)("h4",{id:"aprendizado-por-refor\xe7o-a-partir-de-feedback-humano-arfh"},"Aprendizado por Refor\xe7o a partir de Feedback Humano (ARFH)"),(0,r.kt)("p",null,"ARFH \xe9 um m\xe9todo para ajustar LLMs de acordo com dados de prefer\xeancia humana.\nEm ingl\xeas o termo \xe9 conhecido como Reinforcement Learning from Human Feedback (RLHF)."),(0,r.kt)("div",{className:"footnotes"},(0,r.kt)("hr",{parentName:"div"}),(0,r.kt)("ol",{parentName:"div"},(0,r.kt)("li",{parentName:"ol",id:"fn-1"},"Branch, H. J., Cefalu, J. R., McHugh, J., Hujer, L., Bahl, A., del Castillo Iglesias, D., Heichman, R., & Darwishi, R. (2022). Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")),(0,r.kt)("li",{parentName:"ol",id:"fn-2"},"Schick, T., & Sch\xfctze, H. (2020). Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference.\n",(0,r.kt)("a",{parentName:"li",href:"#fnref-2",className:"footnote-backref"},"\u21a9")))))}c.isMDXComponent=!0}}]);