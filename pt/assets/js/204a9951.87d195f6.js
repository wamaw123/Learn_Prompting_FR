"use strict";(self.webpackChunkpromptgineering=self.webpackChunkpromptgineering||[]).push([[964],{3905:(e,o,a)=>{a.d(o,{Zo:()=>m,kt:()=>g});var t=a(67294);function r(e,o,a){return o in e?Object.defineProperty(e,o,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[o]=a,e}function n(e,o){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);o&&(t=t.filter((function(o){return Object.getOwnPropertyDescriptor(e,o).enumerable}))),a.push.apply(a,t)}return a}function s(e){for(var o=1;o<arguments.length;o++){var a=null!=arguments[o]?arguments[o]:{};o%2?n(Object(a),!0).forEach((function(o){r(e,o,a[o])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(o){Object.defineProperty(e,o,Object.getOwnPropertyDescriptor(a,o))}))}return e}function i(e,o){if(null==e)return{};var a,t,r=function(e,o){if(null==e)return{};var a,t,r={},n=Object.keys(e);for(t=0;t<n.length;t++)a=n[t],o.indexOf(a)>=0||(r[a]=e[a]);return r}(e,o);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(t=0;t<n.length;t++)a=n[t],o.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var d=t.createContext({}),c=function(e){var o=t.useContext(d),a=o;return e&&(a="function"==typeof e?e(o):s(s({},o),e)),a},m=function(e){var o=c(e.components);return t.createElement(d.Provider,{value:o},e.children)},p="mdxType",l={inlineCode:"code",wrapper:function(e){var o=e.children;return t.createElement(t.Fragment,{},o)}},u=t.forwardRef((function(e,o){var a=e.components,r=e.mdxType,n=e.originalType,d=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),p=c(a),u=r,g=p["".concat(d,".").concat(u)]||p[u]||l[u]||n;return a?t.createElement(g,s(s({ref:o},m),{},{components:a})):t.createElement(g,s({ref:o},m))}));function g(e,o){var a=arguments,r=o&&o.mdxType;if("string"==typeof e||r){var n=a.length,s=new Array(n);s[0]=u;var i={};for(var d in o)hasOwnProperty.call(o,d)&&(i[d]=o[d]);i.originalType=e,i[p]="string"==typeof e?e:r,s[1]=i;for(var c=2;c<n;c++)s[c]=a[c];return t.createElement.apply(null,s)}return t.createElement.apply(null,a)}u.displayName="MDXCreateElement"},97445:(e,o,a)=>{a.r(o),a.d(o,{assets:()=>d,contentTitle:()=>s,default:()=>l,frontMatter:()=>n,metadata:()=>i,toc:()=>c});var t=a(87462),r=(a(67294),a(3905));const n={sidebar_position:7,locale:"pt-BR"},s="\ud83d\udfe1 Lidando com Conte\xfados Extensos",i={unversionedId:"intermediate/long_form_content",id:"intermediate/long_form_content",title:"\ud83d\udfe1 Lidando com Conte\xfados Extensos",description:"Lidar com conte\xfado de extens\xe3o longa pode ser dif\xedcil, pois os modelos t\xeam um limite de contexto. Vamos aprender algumas estrat\xe9gias para lidar efetivamente com conte\xfados extensos.",source:"@site/i18n/pt/docusaurus-plugin-content-docs/current/intermediate/long_form_content.md",sourceDirName:"intermediate",slug:"/intermediate/long_form_content",permalink:"/pt/docs/intermediate/long_form_content",draft:!1,editUrl:"https://github.com/trigaten/promptgineering/tree/v1.2.3/docs/intermediate/long_form_content.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{sidebar_position:7,locale:"pt-BR"},sidebar:"tutorialSidebar",previous:{title:"\ud83d\udfe1 Prompts to Tipo Menor para o Maior",permalink:"/pt/docs/intermediate/least_to_most"},next:{title:"\ud83d\udfe1 Revisiting Roles",permalink:"/pt/docs/intermediate/revisiting_roles"}},d={},c=[{value:"1. Pr\xe9-processamento do Texto",id:"1-pr\xe9-processamento-do-texto",level:2},{value:"2. Abordagem de Segmenta\xe7\xe3o e Itera\xe7\xe3o",id:"2-abordagem-de-segmenta\xe7\xe3o-e-itera\xe7\xe3o",level:2},{value:"3. P\xf3s-processamento e Refinamento das Respostas",id:"3-p\xf3s-processamento-e-refinamento-das-respostas",level:2},{value:"4.  Utilizando assistentes de IA com suporte a contextos mais longos",id:"4--utilizando-assistentes-de-ia-com-suporte-a-contextos-mais-longos",level:2},{value:"5. Bibliotecas de C\xf3digo",id:"5-bibliotecas-de-c\xf3digo",level:2},{value:"Conclus\xe3o",id:"conclus\xe3o",level:2}],m={toc:c},p="wrapper";function l(e){let{components:o,...a}=e;return(0,r.kt)(p,(0,t.Z)({},m,a,{components:o,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"-lidando-com-conte\xfados-extensos"},"\ud83d\udfe1 Lidando com Conte\xfados Extensos"),(0,r.kt)("p",null,"Lidar com conte\xfado de extens\xe3o longa pode ser dif\xedcil, pois os modelos t\xeam um limite de contexto. Vamos aprender algumas estrat\xe9gias para lidar efetivamente com conte\xfados extensos."),(0,r.kt)("h2",{id:"1-pr\xe9-processamento-do-texto"},"1. Pr\xe9-processamento do Texto"),(0,r.kt)("p",null,"Antes de fornecer o conte\xfado de longa extens\xe3o a um modelo de linguagem, \xe9 \xfatil pr\xe9-processar o texto para reduzir seu tamanho e complexidade. Algumas estrat\xe9gias para pr\xe9-processamento incluem:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Remover se\xe7\xf5es ou par\xe1grafos desnecess\xe1rios que n\xe3o s\xe3o relevantes ou contribuem para a mensagem principal. Isso pode ajudar a priorizar o conte\xfado mais importante."),(0,r.kt)("li",{parentName:"ul"},"Resumir o texto extraindo pontos-chave ou usando t\xe9cnicas de resumos autom\xe1ticos. Isso pode fornecer uma vis\xe3o geral concisa das ideias principais.")),(0,r.kt)("p",null,"Essas etapas de pr\xe9-processamento podem ajudar a reduzir o tamanho do conte\xfado e melhorar a capacidade do modelo de compreender e gerar respostas."),(0,r.kt)("h2",{id:"2-abordagem-de-segmenta\xe7\xe3o-e-itera\xe7\xe3o"},"2. Abordagem de Segmenta\xe7\xe3o e Itera\xe7\xe3o"),(0,r.kt)("p",null,"Em vez de fornecer todo o conte\xfado de longa extens\xe3o ao modelo de uma vez s\xf3, \xe9 poss\xedvel dividi-lo em partes ou se\xe7\xf5es menores. Essas partes podem ser processadas individualmente, permitindo que o modelo se concentre em uma se\xe7\xe3o espec\xedfica de cada vez."),(0,r.kt)("p",null,"Uma abordagem iterativa pode ser adotada para lidar com conte\xfado de longa extens\xe3o. O modelo pode gerar respostas para cada parte do texto, e a sa\xedda gerada pode ser incorporada como parte da entrada para a pr\xf3xima parte. Dessa forma, a conversa com o modelo de linguagem pode progredir de maneira passo a passo, gerenciando efetivamente o comprimento da conversa."),(0,r.kt)("p",null,"managing the length of the conversation."),(0,r.kt)("h2",{id:"3-p\xf3s-processamento-e-refinamento-das-respostas"},"3. P\xf3s-processamento e Refinamento das Respostas"),(0,r.kt)("p",null,"As respostas iniciais geradas pelo modelo podem ser longas ou conter informa\xe7\xf5es desnecess\xe1rias. \xc9 importante realizar um p\xf3s-processamento nessas respostas para refin\xe1-las e condens\xe1-las."),(0,r.kt)("p",null,"Algumas t\xe9cnicas de p\xf3s-processamento incluem:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Remover informa\xe7\xf5es redundantes ou repetitivas."),(0,r.kt)("li",{parentName:"ul"},"Extrair as partes mais relevantes da resposta."),(0,r.kt)("li",{parentName:"ul"},"Reorganizar a resposta para melhorar a clareza e coer\xeancia.")),(0,r.kt)("p",null,"Ao refinar as respostas, o conte\xfado gerado pode ficar mais conciso e mais f\xe1cil de entender."),(0,r.kt)("h2",{id:"4--utilizando-assistentes-de-ia-com-suporte-a-contextos-mais-longos"},"4.  Utilizando assistentes de IA com suporte a contextos mais longos"),(0,r.kt)("p",null,"Embora alguns modelos de linguagem tenham limita\xe7\xf5es de comprimento de contexto, existem assistentes de IA, como o GPT-4 da OpenAI e o ",(0,r.kt)("a",{parentName:"p",href:"https://www.anthropic.com/index/100k-context-windows"},"Claude da Anthropic"),", que suportam conversas mais longas. Esses assistentes podem lidar com conte\xfado extenso de forma mais eficaz e fornecer respostas mais precisas sem a necessidade de solu\xe7\xf5es complicadas."),(0,r.kt)("h2",{id:"5-bibliotecas-de-c\xf3digo"},"5. Bibliotecas de C\xf3digo"),(0,r.kt)("p",null,"Bibliotecas Python, como o ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/jerryjliu/llama_index"},"Llama Index")," e o ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/langchain-ai/langchain"},"Langchain"),', podem ser usadas para lidar com conte\xfado extenso. Em particular, o GPT Index pode "indexar" o conte\xfado em partes menores e, em seguida, realizar uma busca por vetores para encontrar qual parte do conte\xfado \xe9 mais relevante e us\xe1-la exclusivamente. O Langchain pode realizar resumos recursivos sobre partes do texto, resumindo uma parte e incluindo-a na pr\xf3xima parte a ser resumida.'),(0,r.kt)("h2",{id:"conclus\xe3o"},"Conclus\xe3o"),(0,r.kt)("p",null,"Lidar com conte\xfado extenso o pode ser desafiador, mas ao empregar essas estrat\xe9gias, voc\xea pode gerenciar e navegar efetivamente pelo conte\xfado com a ajuda de modelos de linguagem. Lembre-se de experimentar, iterar e aperfei\xe7oar sua abordagem para determinar a estrat\xe9gia mais eficaz para suas necessidades espec\xedficas."))}l.isMDXComponent=!0}}]);